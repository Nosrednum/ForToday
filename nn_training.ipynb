{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nosrednum/ForToday/blob/master/nn_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3psnfBNli5L"
      },
      "source": [
        "import os \n",
        "import urllib.request \n",
        "import tensorflow as tf\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import cv2 \n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras import activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9UQ5aGllsv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410f4601-f06d-495e-b12b-7d8513ff3232"
      },
      "source": [
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/sebastiandiazmujica/gis-ml/master/\"\n",
        "TRAINING_PATH = os.path.join(\"datasets\", \"training\")\n",
        "TRAINING_URL = DOWNLOAD_ROOT + \"datasets/training/arroz.csv\"\n",
        "\n",
        "'''\n",
        "Crea el directorio de los datos, y descarga los datos (.csv) en la carpeta training\n",
        "'''\n",
        "os.makedirs(TRAINING_PATH, exist_ok = True)\n",
        "archive_path = os.path.join(TRAINING_PATH, \"arroz.csv\")\n",
        "urllib.request.urlretrieve(TRAINING_URL, archive_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('datasets/training/arroz.csv', <http.client.HTTPMessage at 0x7f171bf46320>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mSh3zXnmCZ8"
      },
      "source": [
        "INPUT_SIZE = 7\n",
        "NUM_CLASES = 11\n",
        "data = pd.read_csv(\"datasets/training/arroz.csv\", sep=';', skiprows=0)\n",
        "\n",
        "def create_training_data():\n",
        "  X = data.iloc[:, [2,3,4,5,6,7,8]].values\n",
        "  y = data.iloc[:,-1].values\n",
        "\n",
        "  sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
        "  \n",
        "  for train_index, test_val_index in sss.split(X, y):\n",
        "    X_train, X_test_val = preprocessing.scale(X[train_index]), X[test_val_index]\n",
        "    y_train, y_test_val = tf.one_hot(y[train_index]-1, NUM_CLASES), y[test_val_index]\n",
        "\n",
        "  sss2 =StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n",
        "\n",
        "  for  validation_index, test_index in sss2.split(X_test_val, y_test_val):\n",
        "    X_test, X_val = preprocessing.scale(X_test_val[test_index]), preprocessing.scale(X_test_val[validation_index])\n",
        "    y_test, y_val = tf.one_hot(y_test_val[test_index]-1, NUM_CLASES), tf.one_hot(y_test_val[validation_index]-1, NUM_CLASES)\n",
        "\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdO3sq7Omb3S"
      },
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = create_training_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rayYKuweo650"
      },
      "source": [
        "Se prueban como hiperparametros\n",
        "- inicializador: glorot normal\n",
        "- activacion: relu\n",
        "- forma de la red: [(11, 13, 11), (11,13,13,11), (11,13,15,13,11)]\n",
        "- optimizador: [rms, adam]\n",
        "  - learning rate: [1e-3:1e-1]\n",
        "  - beta: [1-1e-1:1-1e-3]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6UeER-nmdmb"
      },
      "source": [
        "# se importan las librerias estandar\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs_6Xhd2an_g"
      },
      "source": [
        "# se importa de tensorflow lo necesario para crear una red secuancial\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtmCs0I2aoue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5152f2c1-c493-4e4c-e43f-24435316d561"
      },
      "source": [
        "!pip install scikit-optimize #Instalación del optimizador de modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i2_udHCbTQ1"
      },
      "source": [
        "import skopt #optimizador global que busca minimizar el valor pasado por parametro\n",
        "from skopt import gp_minimize, forest_minimize\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from skopt.plots import plot_convergence\n",
        "from skopt.plots import plot_objective, plot_evaluations\n",
        "from skopt.plots import plot_histogram, plot_objective_2D\n",
        "from skopt.utils import use_named_args"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8UELT7SbUDQ"
      },
      "source": [
        "#creamos una dimension para cada hiperparametro\n",
        "#la dimensión es un rango de valores para los cuales se tomarán muestras y se variará sobre ellos\n",
        "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform', name='learning_rate')\n",
        "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
        "dim_num_dense_nodes = Integer(low=5, high=64, name='num_dense_nodes')\n",
        "dim_activation = Categorical(categories=['relu'], name='activation')#, 'sigmoid'], name='activation')\n",
        "#cramos una lista de dimensiones (el orden importa)\n",
        "dimensions = [dim_learning_rate,\n",
        "              dim_num_dense_layers,\n",
        "              dim_num_dense_nodes,\n",
        "              dim_activation]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcRnsYV3dzAM"
      },
      "source": [
        "def log_dir_name(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
        "  '''\n",
        "    Inserta en la carpeta el log correspondiente a una prueba con determinados\n",
        "    hiperparametros\n",
        "  '''\n",
        "    # The dir-name for the TensorBoard log-dir.\n",
        "  s = \"./hplog/lr_{0:.0e}_({1}:{2})_{3}/\"\n",
        "  # Insert all the hyper-parameters in the dir-name.\n",
        "  log_dir = s.format(learning_rate,\n",
        "                     num_dense_layers,\n",
        "                     num_dense_nodes,\n",
        "                     activation)\n",
        "  return log_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWF-BjJccaFm"
      },
      "source": [
        "INPUT_SIZE=7\n",
        "OUTPUT_SIZE=11\n",
        "def create_model(learning_rate, num_dense_layers,\n",
        "                 num_dense_nodes, activation):\n",
        "    \"\"\"\n",
        "    Creación del modelo a optimizar\n",
        "    Hyper-parameters:\n",
        "    learning_rate:     Learning-rate for the optimizer.\n",
        "    num_dense_layers:  Number of dense layers.\n",
        "    num_dense_nodes:   Number of nodes in each dense layer.\n",
        "    activation:        Activation function for all layers.\n",
        "    \"\"\"    \n",
        "    # Crea un modelo secuencial vacio para pooder manipular su estructura\n",
        "    model = Sequential()\n",
        "\n",
        "    # Añade la capa de entrada a la red\n",
        "    model.add(InputLayer(input_shape=(INPUT_SIZE,)))\n",
        "\n",
        "    # Añade capas densamente conectadas entre 1 y num_dense_layers+1.\n",
        "    # Buscamos optimizar este valor (es un hiperparametro)\n",
        "    #la capa se añade con la activación y tamaño pasados por parametro\n",
        "    for i in range(num_dense_layers):\n",
        "        name = 'layer_dense_{0}'.format(i+1)\n",
        "        model.add(Dense(num_dense_nodes,\n",
        "                        activation=activation,\n",
        "                        name=name))\n",
        "    # Ultima capa densamente conectada con activación softmax\n",
        "    # usada para clasificación.\n",
        "    model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
        "    \n",
        "    # Utilizando los optimizadores hallaremos, cuando menos la mejor learning rate\n",
        "    optimizer = RMSprop(learning_rate=learning_rate )\n",
        "    #optimizer = Adam(lr=learning_rate)\n",
        "    \n",
        "    # Compilamos el modelo en keras para luego entrenarlo\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxIQTXynfST4"
      },
      "source": [
        "path_best_model = 'nn_best_model.h5' # archivo con el mejor modelo hallado\n",
        "best_accuracy = 0.0 #mejor accuracy encontrado para el mejor modelo\n",
        "epochs = 20\n",
        "\n",
        "@use_named_args(dimensions=dimensions)\n",
        "def fitness(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
        "    # Antes de empezar a ajustar se imprimen los argumentos de los hiperparametros\n",
        "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
        "    print('num_dense_layers:', num_dense_layers)\n",
        "    print('num_dense_nodes:', num_dense_nodes)\n",
        "    print('activation:', activation)\n",
        "    print()\n",
        "    \n",
        "    # Crea el modelo con los hiperparametros (usa el método definido arriba)\n",
        "    model = create_model(learning_rate=learning_rate,\n",
        "                         num_dense_layers=num_dense_layers,\n",
        "                         num_dense_nodes=num_dense_nodes,\n",
        "                         activation=activation)\n",
        "\n",
        "    # da el nombre para el log de tensorboard\n",
        "    log_dir = log_dir_name(learning_rate, num_dense_layers,\n",
        "                           num_dense_nodes, activation)\n",
        "    \n",
        "    # Crea el callback para el log de tensorboard\n",
        "    callback_log = TensorBoard(\n",
        "        log_dir=log_dir,\n",
        "        histogram_freq=0,\n",
        "        write_graph=True,\n",
        "        write_grads=False,\n",
        "        write_images=False)\n",
        "   \n",
        "    # Entrena el modelo.\n",
        "    history = model.fit(x=X_train,\n",
        "                        y=y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=128,\n",
        "                        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    #                    callbacks=[callback_log])\n",
        "\n",
        "    # Obtiene la precición despues del último paso (en validación)\n",
        "    accuracy = history.history['val_accuracy'][-1]\n",
        "    print()\n",
        "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
        "    print()\n",
        "\n",
        "    # Actualizamos el mejor valor y guardamos el modelo (si es mejor)\n",
        "    global best_accuracy\n",
        "    if accuracy > best_accuracy:\n",
        "        model.save(path_best_model)\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "    # borra el modelo por memoria y caché\n",
        "    del model\n",
        "    # Limpia keras para hacer un flush de los modelos\n",
        "    K.clear_session()\n",
        "    \n",
        "    # Optimiza al minimo\n",
        "    return -accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdetTCdpgbpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a624fb2c-f1af-4518-c81e-6d0a8dece07a"
      },
      "source": [
        "#Prueba de entrenamiento\n",
        "default_parameters = [4e-3, 2, 16, 'relu']\n",
        "#fitnes es la función que entrena el modelo, limpia la sesión, y lo guarda si mejora el accuracy previo\n",
        "fitness(x=default_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate: 4.0e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 16\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8130 - accuracy: 0.7175 - val_loss: 0.6855 - val_accuracy: 0.7678\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6569 - accuracy: 0.7713 - val_loss: 0.6322 - val_accuracy: 0.7775\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6238 - accuracy: 0.7809 - val_loss: 0.6176 - val_accuracy: 0.7829\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6035 - accuracy: 0.7883 - val_loss: 0.5968 - val_accuracy: 0.7909\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5929 - accuracy: 0.7923 - val_loss: 0.6606 - val_accuracy: 0.7661\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5856 - accuracy: 0.7948 - val_loss: 0.5916 - val_accuracy: 0.7913\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5800 - accuracy: 0.7967 - val_loss: 0.5930 - val_accuracy: 0.7863\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5750 - accuracy: 0.7988 - val_loss: 0.6058 - val_accuracy: 0.7916\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5713 - accuracy: 0.8001 - val_loss: 0.5705 - val_accuracy: 0.8002\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5677 - accuracy: 0.8017 - val_loss: 0.5726 - val_accuracy: 0.8017\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5647 - accuracy: 0.8031 - val_loss: 0.5631 - val_accuracy: 0.8070\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5617 - accuracy: 0.8045 - val_loss: 0.5800 - val_accuracy: 0.8019\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5586 - accuracy: 0.8055 - val_loss: 0.5662 - val_accuracy: 0.8059\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5556 - accuracy: 0.8068 - val_loss: 0.5749 - val_accuracy: 0.7963\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5532 - accuracy: 0.8080 - val_loss: 0.5593 - val_accuracy: 0.8103\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5509 - accuracy: 0.8092 - val_loss: 0.5696 - val_accuracy: 0.8023\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5485 - accuracy: 0.8098 - val_loss: 0.5824 - val_accuracy: 0.7997\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5448 - accuracy: 0.8111 - val_loss: 0.5668 - val_accuracy: 0.8027\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5405 - accuracy: 0.8122 - val_loss: 0.5450 - val_accuracy: 0.8097\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5381 - accuracy: 0.8129 - val_loss: 0.5445 - val_accuracy: 0.8133\n",
            "\n",
            "Accuracy: 81.33%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.8132829070091248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSVrGYFHpBoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758b620a-89c1-4024-a9a8-7fb6d541141b"
      },
      "source": [
        "#imprime el tiempo de ejecución\n",
        "%%time \n",
        "\n",
        "# Ejecuta una busqueda entre las dimensiones alterando la función fitness\n",
        "# con el objetivo de minimizar el valor a optimizar, en este caso el accuracy negativo,\n",
        "# y guarda el registro de sus iteraciones para poder comparar\n",
        "search_result = gp_minimize(func=fitness,\n",
        "                            dimensions=dimensions,\n",
        "                            acq_func='EI', # Expected Improvement.\n",
        "                            n_calls=40,\n",
        "                            x0=default_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate: 4.0e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 16\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7813 - accuracy: 0.7252 - val_loss: 0.6861 - val_accuracy: 0.7556\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6582 - accuracy: 0.7689 - val_loss: 0.6393 - val_accuracy: 0.7757\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6276 - accuracy: 0.7785 - val_loss: 0.6565 - val_accuracy: 0.7697\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6059 - accuracy: 0.7866 - val_loss: 0.6224 - val_accuracy: 0.7796\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5900 - accuracy: 0.7928 - val_loss: 0.5761 - val_accuracy: 0.7980\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5766 - accuracy: 0.7974 - val_loss: 0.5899 - val_accuracy: 0.7895\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5682 - accuracy: 0.7995 - val_loss: 0.5662 - val_accuracy: 0.8001\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5614 - accuracy: 0.8024 - val_loss: 0.5630 - val_accuracy: 0.8023\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5560 - accuracy: 0.8044 - val_loss: 0.5591 - val_accuracy: 0.8026\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5505 - accuracy: 0.8067 - val_loss: 0.5642 - val_accuracy: 0.8007\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5469 - accuracy: 0.8084 - val_loss: 0.5550 - val_accuracy: 0.8043\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5432 - accuracy: 0.8098 - val_loss: 0.5629 - val_accuracy: 0.8038\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5406 - accuracy: 0.8112 - val_loss: 0.5534 - val_accuracy: 0.8096\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5392 - accuracy: 0.8118 - val_loss: 0.5441 - val_accuracy: 0.8104\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5383 - accuracy: 0.8119 - val_loss: 0.5649 - val_accuracy: 0.8040\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5369 - accuracy: 0.8125 - val_loss: 0.5571 - val_accuracy: 0.8025\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5355 - accuracy: 0.8127 - val_loss: 0.5362 - val_accuracy: 0.8138\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5343 - accuracy: 0.8134 - val_loss: 0.5397 - val_accuracy: 0.8118\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5317 - accuracy: 0.8140 - val_loss: 0.5335 - val_accuracy: 0.8124\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5307 - accuracy: 0.8149 - val_loss: 0.5415 - val_accuracy: 0.8135\n",
            "\n",
            "Accuracy: 81.35%\n",
            "\n",
            "learning rate: 2.2e-06\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 27\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.3865 - accuracy: 0.1311 - val_loss: 2.3530 - val_accuracy: 0.1642\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.3227 - accuracy: 0.2074 - val_loss: 2.2915 - val_accuracy: 0.2504\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.2598 - accuracy: 0.3167 - val_loss: 2.2277 - val_accuracy: 0.3829\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.1943 - accuracy: 0.4011 - val_loss: 2.1595 - val_accuracy: 0.4153\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 2.1234 - accuracy: 0.4254 - val_loss: 2.0862 - val_accuracy: 0.4303\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.0487 - accuracy: 0.4329 - val_loss: 2.0109 - val_accuracy: 0.4339\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.9733 - accuracy: 0.4340 - val_loss: 1.9354 - val_accuracy: 0.4344\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.8977 - accuracy: 0.4338 - val_loss: 1.8599 - val_accuracy: 0.4344\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.8226 - accuracy: 0.4336 - val_loss: 1.7854 - val_accuracy: 0.4327\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.7493 - accuracy: 0.4329 - val_loss: 1.7138 - val_accuracy: 0.4407\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.6802 - accuracy: 0.4505 - val_loss: 1.6474 - val_accuracy: 0.4640\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.6164 - accuracy: 0.4741 - val_loss: 1.5862 - val_accuracy: 0.4821\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.5581 - accuracy: 0.4851 - val_loss: 1.5307 - val_accuracy: 0.4861\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.5052 - accuracy: 0.4877 - val_loss: 1.4802 - val_accuracy: 0.4870\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4575 - accuracy: 0.4900 - val_loss: 1.4351 - val_accuracy: 0.4927\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4153 - accuracy: 0.4998 - val_loss: 1.3955 - val_accuracy: 0.5082\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.3779 - accuracy: 0.5144 - val_loss: 1.3601 - val_accuracy: 0.5194\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.3452 - accuracy: 0.5230 - val_loss: 1.3298 - val_accuracy: 0.5253\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.3174 - accuracy: 0.5275 - val_loss: 1.3043 - val_accuracy: 0.5285\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.2938 - accuracy: 0.5284 - val_loss: 1.2824 - val_accuracy: 0.5294\n",
            "\n",
            "Accuracy: 52.94%\n",
            "\n",
            "learning rate: 1.5e-06\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 40\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.3353 - accuracy: 0.1636 - val_loss: 2.2902 - val_accuracy: 0.1798\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.2529 - accuracy: 0.1859 - val_loss: 2.2185 - val_accuracy: 0.1884\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.1918 - accuracy: 0.1856 - val_loss: 2.1664 - val_accuracy: 0.1826\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.1441 - accuracy: 0.2479 - val_loss: 2.1208 - val_accuracy: 0.3008\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.0976 - accuracy: 0.3126 - val_loss: 2.0725 - val_accuracy: 0.3154\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.0469 - accuracy: 0.3146 - val_loss: 2.0191 - val_accuracy: 0.3119\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.9913 - accuracy: 0.3111 - val_loss: 1.9614 - val_accuracy: 0.3093\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.9327 - accuracy: 0.3083 - val_loss: 1.9020 - val_accuracy: 0.3062\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.8736 - accuracy: 0.3061 - val_loss: 1.8435 - val_accuracy: 0.3058\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.8166 - accuracy: 0.3079 - val_loss: 1.7879 - val_accuracy: 0.3092\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.7629 - accuracy: 0.3136 - val_loss: 1.7357 - val_accuracy: 0.3150\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.7122 - accuracy: 0.3197 - val_loss: 1.6865 - val_accuracy: 0.3213\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.6647 - accuracy: 0.3266 - val_loss: 1.6404 - val_accuracy: 0.3294\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.6202 - accuracy: 0.3368 - val_loss: 1.5973 - val_accuracy: 0.3408\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.5785 - accuracy: 0.3534 - val_loss: 1.5567 - val_accuracy: 0.3929\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.5393 - accuracy: 0.4335 - val_loss: 1.5187 - val_accuracy: 0.4543\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.5026 - accuracy: 0.4581 - val_loss: 1.4831 - val_accuracy: 0.4533\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4684 - accuracy: 0.4477 - val_loss: 1.4500 - val_accuracy: 0.4426\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4365 - accuracy: 0.4507 - val_loss: 1.4191 - val_accuracy: 0.4592\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4070 - accuracy: 0.4753 - val_loss: 1.3909 - val_accuracy: 0.4958\n",
            "\n",
            "Accuracy: 49.58%\n",
            "\n",
            "learning rate: 1.2e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 21\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9032 - accuracy: 0.6762 - val_loss: 0.7254 - val_accuracy: 0.7437\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6856 - accuracy: 0.7616 - val_loss: 0.6694 - val_accuracy: 0.7654\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6530 - accuracy: 0.7732 - val_loss: 0.6444 - val_accuracy: 0.7771\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6366 - accuracy: 0.7781 - val_loss: 0.6335 - val_accuracy: 0.7803\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6232 - accuracy: 0.7819 - val_loss: 0.6184 - val_accuracy: 0.7839\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6116 - accuracy: 0.7853 - val_loss: 0.6091 - val_accuracy: 0.7846\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6009 - accuracy: 0.7885 - val_loss: 0.5969 - val_accuracy: 0.7904\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5910 - accuracy: 0.7918 - val_loss: 0.5858 - val_accuracy: 0.7952\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5816 - accuracy: 0.7949 - val_loss: 0.5758 - val_accuracy: 0.7983\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5725 - accuracy: 0.7982 - val_loss: 0.5704 - val_accuracy: 0.7999\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5655 - accuracy: 0.8016 - val_loss: 0.5726 - val_accuracy: 0.7980\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5602 - accuracy: 0.8037 - val_loss: 0.5602 - val_accuracy: 0.8046\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5557 - accuracy: 0.8055 - val_loss: 0.5525 - val_accuracy: 0.8082\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5515 - accuracy: 0.8074 - val_loss: 0.5525 - val_accuracy: 0.8068\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5481 - accuracy: 0.8089 - val_loss: 0.5451 - val_accuracy: 0.8106\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5451 - accuracy: 0.8091 - val_loss: 0.5541 - val_accuracy: 0.8055\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5422 - accuracy: 0.8105 - val_loss: 0.5457 - val_accuracy: 0.8086\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5393 - accuracy: 0.8109 - val_loss: 0.5442 - val_accuracy: 0.8103\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5370 - accuracy: 0.8124 - val_loss: 0.5382 - val_accuracy: 0.8115\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5344 - accuracy: 0.8136 - val_loss: 0.5369 - val_accuracy: 0.8128\n",
            "\n",
            "Accuracy: 81.28%\n",
            "\n",
            "learning rate: 7.5e-05\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 26\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4681 - accuracy: 0.4629 - val_loss: 1.0741 - val_accuracy: 0.5959\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.9680 - accuracy: 0.6412 - val_loss: 0.8946 - val_accuracy: 0.6681\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8532 - accuracy: 0.6879 - val_loss: 0.8195 - val_accuracy: 0.7031\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7914 - accuracy: 0.7175 - val_loss: 0.7694 - val_accuracy: 0.7252\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7509 - accuracy: 0.7301 - val_loss: 0.7379 - val_accuracy: 0.7362\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 2ms/step - loss: 0.7259 - accuracy: 0.7372 - val_loss: 0.7194 - val_accuracy: 0.7397\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7094 - accuracy: 0.7417 - val_loss: 0.7050 - val_accuracy: 0.7413\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6977 - accuracy: 0.7451 - val_loss: 0.6955 - val_accuracy: 0.7443\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6889 - accuracy: 0.7481 - val_loss: 0.6862 - val_accuracy: 0.7508\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6815 - accuracy: 0.7505 - val_loss: 0.6800 - val_accuracy: 0.7520\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6751 - accuracy: 0.7529 - val_loss: 0.6750 - val_accuracy: 0.7518\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6694 - accuracy: 0.7548 - val_loss: 0.6682 - val_accuracy: 0.7564\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6641 - accuracy: 0.7571 - val_loss: 0.6645 - val_accuracy: 0.7565\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6587 - accuracy: 0.7596 - val_loss: 0.6591 - val_accuracy: 0.7588\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6529 - accuracy: 0.7633 - val_loss: 0.6514 - val_accuracy: 0.7655\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6458 - accuracy: 0.7679 - val_loss: 0.6454 - val_accuracy: 0.7684\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6393 - accuracy: 0.7712 - val_loss: 0.6374 - val_accuracy: 0.7736\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6339 - accuracy: 0.7736 - val_loss: 0.6330 - val_accuracy: 0.7741\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6293 - accuracy: 0.7755 - val_loss: 0.6278 - val_accuracy: 0.7770\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6250 - accuracy: 0.7775 - val_loss: 0.6249 - val_accuracy: 0.7799\n",
            "\n",
            "Accuracy: 77.99%\n",
            "\n",
            "learning rate: 4.0e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 10\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8253 - accuracy: 0.7116 - val_loss: 0.7150 - val_accuracy: 0.7545\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6961 - accuracy: 0.7618 - val_loss: 0.6791 - val_accuracy: 0.7667\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6741 - accuracy: 0.7681 - val_loss: 0.6696 - val_accuracy: 0.7709\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6590 - accuracy: 0.7739 - val_loss: 0.6961 - val_accuracy: 0.7613\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6497 - accuracy: 0.7770 - val_loss: 0.6467 - val_accuracy: 0.7799\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6425 - accuracy: 0.7801 - val_loss: 0.6447 - val_accuracy: 0.7814\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6363 - accuracy: 0.7810 - val_loss: 0.6529 - val_accuracy: 0.7680\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6293 - accuracy: 0.7829 - val_loss: 0.6272 - val_accuracy: 0.7851\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6233 - accuracy: 0.7843 - val_loss: 0.6224 - val_accuracy: 0.7871\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6196 - accuracy: 0.7866 - val_loss: 0.6453 - val_accuracy: 0.7733\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6171 - accuracy: 0.7870 - val_loss: 0.6476 - val_accuracy: 0.7690\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6156 - accuracy: 0.7876 - val_loss: 0.6261 - val_accuracy: 0.7842\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6145 - accuracy: 0.7880 - val_loss: 0.6265 - val_accuracy: 0.7869\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6132 - accuracy: 0.7882 - val_loss: 0.6190 - val_accuracy: 0.7839\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6126 - accuracy: 0.7888 - val_loss: 0.6294 - val_accuracy: 0.7850\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6116 - accuracy: 0.7889 - val_loss: 0.6158 - val_accuracy: 0.7860\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6107 - accuracy: 0.7892 - val_loss: 0.6203 - val_accuracy: 0.7887\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6100 - accuracy: 0.7893 - val_loss: 0.6139 - val_accuracy: 0.7890\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6093 - accuracy: 0.7893 - val_loss: 0.6062 - val_accuracy: 0.7913\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6088 - accuracy: 0.7895 - val_loss: 0.6166 - val_accuracy: 0.7900\n",
            "\n",
            "Accuracy: 79.00%\n",
            "\n",
            "learning rate: 1.6e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 58\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6836 - accuracy: 0.7536 - val_loss: 0.5870 - val_accuracy: 0.7907\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5238 - accuracy: 0.8125 - val_loss: 0.4883 - val_accuracy: 0.8259\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4597 - accuracy: 0.8355 - val_loss: 0.4560 - val_accuracy: 0.8367\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4223 - accuracy: 0.8491 - val_loss: 0.4979 - val_accuracy: 0.8268\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4007 - accuracy: 0.8575 - val_loss: 0.3801 - val_accuracy: 0.8629\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3876 - accuracy: 0.8629 - val_loss: 0.3823 - val_accuracy: 0.8664\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3809 - accuracy: 0.8664 - val_loss: 0.4258 - val_accuracy: 0.8528\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3779 - accuracy: 0.8676 - val_loss: 0.3870 - val_accuracy: 0.8646\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3780 - accuracy: 0.8686 - val_loss: 0.3985 - val_accuracy: 0.8653\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3808 - accuracy: 0.8684 - val_loss: 0.4145 - val_accuracy: 0.8632\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3829 - accuracy: 0.8684 - val_loss: 0.3834 - val_accuracy: 0.8668\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3868 - accuracy: 0.8675 - val_loss: 0.4054 - val_accuracy: 0.8700\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3921 - accuracy: 0.8669 - val_loss: 0.4298 - val_accuracy: 0.8536\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3937 - accuracy: 0.8666 - val_loss: 0.4199 - val_accuracy: 0.8611\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3933 - accuracy: 0.8663 - val_loss: 0.4125 - val_accuracy: 0.8602\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3989 - accuracy: 0.8658 - val_loss: 0.4301 - val_accuracy: 0.8528\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4205 - accuracy: 0.8657 - val_loss: 0.4174 - val_accuracy: 0.8555\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4032 - accuracy: 0.8643 - val_loss: 0.4540 - val_accuracy: 0.8488\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4087 - accuracy: 0.8639 - val_loss: 0.4763 - val_accuracy: 0.8407\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4187 - accuracy: 0.8643 - val_loss: 0.4702 - val_accuracy: 0.8657\n",
            "\n",
            "Accuracy: 86.57%\n",
            "\n",
            "learning rate: 1.1e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 15\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9985 - accuracy: 0.6424 - val_loss: 0.7635 - val_accuracy: 0.7283\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7245 - accuracy: 0.7471 - val_loss: 0.7015 - val_accuracy: 0.7571\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6848 - accuracy: 0.7632 - val_loss: 0.6759 - val_accuracy: 0.7666\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6652 - accuracy: 0.7689 - val_loss: 0.6622 - val_accuracy: 0.7693\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6482 - accuracy: 0.7739 - val_loss: 0.6432 - val_accuracy: 0.7759\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6368 - accuracy: 0.7765 - val_loss: 0.6381 - val_accuracy: 0.7759\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 2ms/step - loss: 0.6272 - accuracy: 0.7789 - val_loss: 0.6272 - val_accuracy: 0.7780\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6191 - accuracy: 0.7810 - val_loss: 0.6186 - val_accuracy: 0.7803\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6115 - accuracy: 0.7838 - val_loss: 0.6173 - val_accuracy: 0.7821\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6049 - accuracy: 0.7860 - val_loss: 0.6047 - val_accuracy: 0.7876\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5991 - accuracy: 0.7876 - val_loss: 0.6016 - val_accuracy: 0.7859\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5944 - accuracy: 0.7897 - val_loss: 0.5938 - val_accuracy: 0.7908\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5904 - accuracy: 0.7906 - val_loss: 0.5895 - val_accuracy: 0.7944\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5865 - accuracy: 0.7921 - val_loss: 0.5872 - val_accuracy: 0.7918\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5825 - accuracy: 0.7935 - val_loss: 0.5838 - val_accuracy: 0.7933\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5776 - accuracy: 0.7952 - val_loss: 0.5772 - val_accuracy: 0.7939\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5731 - accuracy: 0.7973 - val_loss: 0.5749 - val_accuracy: 0.7964\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5693 - accuracy: 0.7986 - val_loss: 0.5764 - val_accuracy: 0.7980\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5661 - accuracy: 0.7999 - val_loss: 0.5686 - val_accuracy: 0.8007\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5635 - accuracy: 0.8009 - val_loss: 0.5642 - val_accuracy: 0.8001\n",
            "\n",
            "Accuracy: 80.01%\n",
            "\n",
            "learning rate: 5.6e-06\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 20\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.3490 - accuracy: 0.1544 - val_loss: 2.2809 - val_accuracy: 0.2709\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.2124 - accuracy: 0.3146 - val_loss: 2.1447 - val_accuracy: 0.3314\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.0829 - accuracy: 0.3322 - val_loss: 2.0189 - val_accuracy: 0.3350\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.9500 - accuracy: 0.3390 - val_loss: 1.8775 - val_accuracy: 0.3434\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.8051 - accuracy: 0.3496 - val_loss: 1.7331 - val_accuracy: 0.3537\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.6680 - accuracy: 0.3935 - val_loss: 1.6048 - val_accuracy: 0.4108\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.5514 - accuracy: 0.4143 - val_loss: 1.5013 - val_accuracy: 0.4188\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4622 - accuracy: 0.4449 - val_loss: 1.4257 - val_accuracy: 0.4581\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.3993 - accuracy: 0.4703 - val_loss: 1.3737 - val_accuracy: 0.4799\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.3542 - accuracy: 0.4908 - val_loss: 1.3342 - val_accuracy: 0.4994\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.3200 - accuracy: 0.5056 - val_loss: 1.3043 - val_accuracy: 0.5107\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.2924 - accuracy: 0.5156 - val_loss: 1.2784 - val_accuracy: 0.5204\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.2675 - accuracy: 0.5251 - val_loss: 1.2541 - val_accuracy: 0.5300\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.2436 - accuracy: 0.5342 - val_loss: 1.2303 - val_accuracy: 0.5390\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.2205 - accuracy: 0.5432 - val_loss: 1.2080 - val_accuracy: 0.5458\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.1987 - accuracy: 0.5505 - val_loss: 1.1868 - val_accuracy: 0.5533\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.1780 - accuracy: 0.5575 - val_loss: 1.1667 - val_accuracy: 0.5600\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.1583 - accuracy: 0.5641 - val_loss: 1.1475 - val_accuracy: 0.5659\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.1395 - accuracy: 0.5702 - val_loss: 1.1291 - val_accuracy: 0.5724\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.1217 - accuracy: 0.5759 - val_loss: 1.1119 - val_accuracy: 0.5786\n",
            "\n",
            "Accuracy: 57.86%\n",
            "\n",
            "learning rate: 3.0e-05\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 7\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.2922 - accuracy: 0.1977 - val_loss: 2.1860 - val_accuracy: 0.2597\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.1092 - accuracy: 0.2561 - val_loss: 2.0374 - val_accuracy: 0.2529\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.9603 - accuracy: 0.2613 - val_loss: 1.8829 - val_accuracy: 0.2901\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.8092 - accuracy: 0.3533 - val_loss: 1.7381 - val_accuracy: 0.3800\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.6756 - accuracy: 0.3902 - val_loss: 1.6168 - val_accuracy: 0.4117\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.5692 - accuracy: 0.4411 - val_loss: 1.5249 - val_accuracy: 0.4597\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.4894 - accuracy: 0.4604 - val_loss: 1.4553 - val_accuracy: 0.4630\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.4268 - accuracy: 0.4690 - val_loss: 1.3986 - val_accuracy: 0.4799\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.3745 - accuracy: 0.4842 - val_loss: 1.3503 - val_accuracy: 0.4948\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.3294 - accuracy: 0.4953 - val_loss: 1.3081 - val_accuracy: 0.5025\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.2895 - accuracy: 0.5170 - val_loss: 1.2697 - val_accuracy: 0.5455\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.2499 - accuracy: 0.5620 - val_loss: 1.2293 - val_accuracy: 0.5707\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.2088 - accuracy: 0.5761 - val_loss: 1.1875 - val_accuracy: 0.5851\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.1660 - accuracy: 0.5931 - val_loss: 1.1446 - val_accuracy: 0.6011\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 2ms/step - loss: 1.1242 - accuracy: 0.6046 - val_loss: 1.1062 - val_accuracy: 0.6090\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.0904 - accuracy: 0.6101 - val_loss: 1.0769 - val_accuracy: 0.6130\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.0643 - accuracy: 0.6141 - val_loss: 1.0542 - val_accuracy: 0.6164\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.0443 - accuracy: 0.6178 - val_loss: 1.0367 - val_accuracy: 0.6199\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.0287 - accuracy: 0.6210 - val_loss: 1.0227 - val_accuracy: 0.6227\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.0159 - accuracy: 0.6241 - val_loss: 1.0109 - val_accuracy: 0.6268\n",
            "\n",
            "Accuracy: 62.68%\n",
            "\n",
            "learning rate: 5.4e-04\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 14\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.1256 - accuracy: 0.5860 - val_loss: 0.8577 - val_accuracy: 0.6823\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7975 - accuracy: 0.7177 - val_loss: 0.7594 - val_accuracy: 0.7366\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7315 - accuracy: 0.7456 - val_loss: 0.7163 - val_accuracy: 0.7506\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7026 - accuracy: 0.7567 - val_loss: 0.6990 - val_accuracy: 0.7562\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6857 - accuracy: 0.7625 - val_loss: 0.6831 - val_accuracy: 0.7599\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6737 - accuracy: 0.7654 - val_loss: 0.6678 - val_accuracy: 0.7679\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6634 - accuracy: 0.7691 - val_loss: 0.6570 - val_accuracy: 0.7701\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6543 - accuracy: 0.7722 - val_loss: 0.6651 - val_accuracy: 0.7678\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6464 - accuracy: 0.7750 - val_loss: 0.6484 - val_accuracy: 0.7748\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6390 - accuracy: 0.7782 - val_loss: 0.6430 - val_accuracy: 0.7769\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6320 - accuracy: 0.7807 - val_loss: 0.6279 - val_accuracy: 0.7845\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6259 - accuracy: 0.7829 - val_loss: 0.6401 - val_accuracy: 0.7753\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6206 - accuracy: 0.7843 - val_loss: 0.6392 - val_accuracy: 0.7803\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6161 - accuracy: 0.7854 - val_loss: 0.6174 - val_accuracy: 0.7846\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6120 - accuracy: 0.7868 - val_loss: 0.6164 - val_accuracy: 0.7860\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6084 - accuracy: 0.7879 - val_loss: 0.6125 - val_accuracy: 0.7877\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6049 - accuracy: 0.7892 - val_loss: 0.6027 - val_accuracy: 0.7884\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6018 - accuracy: 0.7902 - val_loss: 0.5977 - val_accuracy: 0.7921\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5988 - accuracy: 0.7911 - val_loss: 0.6011 - val_accuracy: 0.7910\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5960 - accuracy: 0.7916 - val_loss: 0.5963 - val_accuracy: 0.7930\n",
            "\n",
            "Accuracy: 79.30%\n",
            "\n",
            "learning rate: 1.0e-02\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7347 - accuracy: 0.7432 - val_loss: 0.9009 - val_accuracy: 0.7153\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6808 - accuracy: 0.7840 - val_loss: 1.2815 - val_accuracy: 0.7385\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6446 - accuracy: 0.7886 - val_loss: 0.9003 - val_accuracy: 0.7404\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6763 - accuracy: 0.7881 - val_loss: 0.6271 - val_accuracy: 0.7939\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.8069 - accuracy: 0.7913 - val_loss: 0.6475 - val_accuracy: 0.7919\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7174 - accuracy: 0.7921 - val_loss: 0.6418 - val_accuracy: 0.7995\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7068 - accuracy: 0.7897 - val_loss: 0.7993 - val_accuracy: 0.7327\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7421 - accuracy: 0.7906 - val_loss: 0.7131 - val_accuracy: 0.7778\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7317 - accuracy: 0.7918 - val_loss: 0.6175 - val_accuracy: 0.8006\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7474 - accuracy: 0.7937 - val_loss: 0.6721 - val_accuracy: 0.7964\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7253 - accuracy: 0.7956 - val_loss: 0.7323 - val_accuracy: 0.7733\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.8142 - accuracy: 0.7913 - val_loss: 0.6538 - val_accuracy: 0.7971\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7298 - accuracy: 0.7910 - val_loss: 0.9531 - val_accuracy: 0.6968\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.8611 - accuracy: 0.7855 - val_loss: 0.8351 - val_accuracy: 0.7543\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 1.0587 - accuracy: 0.7804 - val_loss: 0.9875 - val_accuracy: 0.7859\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.9892 - accuracy: 0.7746 - val_loss: 0.7351 - val_accuracy: 0.7953\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 1.0157 - accuracy: 0.7725 - val_loss: 0.8053 - val_accuracy: 0.7610\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 1.2049 - accuracy: 0.7707 - val_loss: 0.7485 - val_accuracy: 0.7802\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.9196 - accuracy: 0.7714 - val_loss: 0.9104 - val_accuracy: 0.7283\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 1.0518 - accuracy: 0.7712 - val_loss: 0.8556 - val_accuracy: 0.7541\n",
            "\n",
            "Accuracy: 75.41%\n",
            "\n",
            "learning rate: 3.6e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 60\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.8084 - accuracy: 0.7145 - val_loss: 0.6665 - val_accuracy: 0.7615\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6233 - accuracy: 0.7792 - val_loss: 0.5981 - val_accuracy: 0.7881\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5798 - accuracy: 0.7928 - val_loss: 0.5720 - val_accuracy: 0.7970\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5498 - accuracy: 0.8040 - val_loss: 0.5541 - val_accuracy: 0.8021\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5265 - accuracy: 0.8133 - val_loss: 0.5457 - val_accuracy: 0.8086\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5063 - accuracy: 0.8211 - val_loss: 0.5004 - val_accuracy: 0.8223\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 9s 2ms/step - loss: 0.4867 - accuracy: 0.8284 - val_loss: 0.4786 - val_accuracy: 0.8324\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4679 - accuracy: 0.8352 - val_loss: 0.4608 - val_accuracy: 0.8368\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4520 - accuracy: 0.8404 - val_loss: 0.4699 - val_accuracy: 0.8315\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4391 - accuracy: 0.8453 - val_loss: 0.4393 - val_accuracy: 0.8443\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4280 - accuracy: 0.8490 - val_loss: 0.4462 - val_accuracy: 0.8447\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4182 - accuracy: 0.8530 - val_loss: 0.4405 - val_accuracy: 0.8443\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4105 - accuracy: 0.8549 - val_loss: 0.4103 - val_accuracy: 0.8562\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4030 - accuracy: 0.8578 - val_loss: 0.4341 - val_accuracy: 0.8429\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3967 - accuracy: 0.8602 - val_loss: 0.3946 - val_accuracy: 0.8616\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3909 - accuracy: 0.8625 - val_loss: 0.4010 - val_accuracy: 0.8600\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3855 - accuracy: 0.8639 - val_loss: 0.4025 - val_accuracy: 0.8587\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3811 - accuracy: 0.8656 - val_loss: 0.3953 - val_accuracy: 0.8618\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3762 - accuracy: 0.8673 - val_loss: 0.4043 - val_accuracy: 0.8595\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3720 - accuracy: 0.8684 - val_loss: 0.3776 - val_accuracy: 0.8674\n",
            "\n",
            "Accuracy: 86.74%\n",
            "\n",
            "learning rate: 7.4e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 46\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7693 - accuracy: 0.7252 - val_loss: 0.6681 - val_accuracy: 0.7612\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5988 - accuracy: 0.7867 - val_loss: 0.6057 - val_accuracy: 0.7820\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5528 - accuracy: 0.8027 - val_loss: 0.5977 - val_accuracy: 0.7868\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5187 - accuracy: 0.8162 - val_loss: 0.5126 - val_accuracy: 0.8199\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4887 - accuracy: 0.8270 - val_loss: 0.5283 - val_accuracy: 0.8110\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4646 - accuracy: 0.8356 - val_loss: 0.4802 - val_accuracy: 0.8341\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4471 - accuracy: 0.8421 - val_loss: 0.4421 - val_accuracy: 0.8456\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4336 - accuracy: 0.8474 - val_loss: 0.4631 - val_accuracy: 0.8388\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4218 - accuracy: 0.8513 - val_loss: 0.4404 - val_accuracy: 0.8414\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4122 - accuracy: 0.8545 - val_loss: 0.4152 - val_accuracy: 0.8541\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4045 - accuracy: 0.8576 - val_loss: 0.4188 - val_accuracy: 0.8521\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3976 - accuracy: 0.8598 - val_loss: 0.4084 - val_accuracy: 0.8559\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3910 - accuracy: 0.8624 - val_loss: 0.3810 - val_accuracy: 0.8650\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3859 - accuracy: 0.8638 - val_loss: 0.4088 - val_accuracy: 0.8558\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3813 - accuracy: 0.8657 - val_loss: 0.4023 - val_accuracy: 0.8589\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3772 - accuracy: 0.8674 - val_loss: 0.4079 - val_accuracy: 0.8592\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3731 - accuracy: 0.8682 - val_loss: 0.4008 - val_accuracy: 0.8568\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3693 - accuracy: 0.8699 - val_loss: 0.3771 - val_accuracy: 0.8676\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3665 - accuracy: 0.8710 - val_loss: 0.3690 - val_accuracy: 0.8697\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3636 - accuracy: 0.8722 - val_loss: 0.3787 - val_accuracy: 0.8681\n",
            "\n",
            "Accuracy: 86.81%\n",
            "\n",
            "learning rate: 1.6e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8425 - accuracy: 0.7077 - val_loss: 0.7050 - val_accuracy: 0.7596\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6720 - accuracy: 0.7695 - val_loss: 0.6542 - val_accuracy: 0.7737\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6373 - accuracy: 0.7803 - val_loss: 0.6296 - val_accuracy: 0.7795\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6172 - accuracy: 0.7859 - val_loss: 0.6098 - val_accuracy: 0.7865\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6030 - accuracy: 0.7901 - val_loss: 0.5998 - val_accuracy: 0.7909\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5921 - accuracy: 0.7926 - val_loss: 0.5953 - val_accuracy: 0.7894\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5836 - accuracy: 0.7954 - val_loss: 0.5841 - val_accuracy: 0.7931\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5761 - accuracy: 0.7981 - val_loss: 0.5782 - val_accuracy: 0.7975\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5694 - accuracy: 0.8006 - val_loss: 0.5678 - val_accuracy: 0.8009\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5634 - accuracy: 0.8031 - val_loss: 0.5660 - val_accuracy: 0.8023\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5578 - accuracy: 0.8050 - val_loss: 0.5632 - val_accuracy: 0.8032\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5524 - accuracy: 0.8067 - val_loss: 0.5607 - val_accuracy: 0.8039\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5473 - accuracy: 0.8086 - val_loss: 0.5470 - val_accuracy: 0.8082\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5424 - accuracy: 0.8104 - val_loss: 0.5507 - val_accuracy: 0.8055\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5380 - accuracy: 0.8121 - val_loss: 0.5357 - val_accuracy: 0.8137\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5337 - accuracy: 0.8135 - val_loss: 0.5378 - val_accuracy: 0.8103\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5298 - accuracy: 0.8145 - val_loss: 0.5314 - val_accuracy: 0.8144\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5263 - accuracy: 0.8161 - val_loss: 0.5307 - val_accuracy: 0.8126\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5230 - accuracy: 0.8172 - val_loss: 0.5286 - val_accuracy: 0.8139\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5197 - accuracy: 0.8185 - val_loss: 0.5236 - val_accuracy: 0.8155\n",
            "\n",
            "Accuracy: 81.55%\n",
            "\n",
            "learning rate: 6.4e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.7535 - accuracy: 0.7310 - val_loss: 0.6930 - val_accuracy: 0.7482\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5828 - accuracy: 0.7922 - val_loss: 0.5661 - val_accuracy: 0.7999\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5261 - accuracy: 0.8133 - val_loss: 0.5443 - val_accuracy: 0.8037\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4834 - accuracy: 0.8289 - val_loss: 0.5368 - val_accuracy: 0.8099\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4539 - accuracy: 0.8390 - val_loss: 0.4463 - val_accuracy: 0.8428\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4316 - accuracy: 0.8473 - val_loss: 0.4258 - val_accuracy: 0.8525\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4130 - accuracy: 0.8540 - val_loss: 0.4542 - val_accuracy: 0.8379\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3995 - accuracy: 0.8588 - val_loss: 0.4045 - val_accuracy: 0.8567\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3883 - accuracy: 0.8621 - val_loss: 0.3812 - val_accuracy: 0.8643\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3783 - accuracy: 0.8658 - val_loss: 0.3925 - val_accuracy: 0.8630\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3703 - accuracy: 0.8687 - val_loss: 0.3996 - val_accuracy: 0.8617\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3633 - accuracy: 0.8718 - val_loss: 0.3653 - val_accuracy: 0.8706\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3574 - accuracy: 0.8737 - val_loss: 0.3707 - val_accuracy: 0.8686\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3514 - accuracy: 0.8758 - val_loss: 0.3802 - val_accuracy: 0.8638\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3462 - accuracy: 0.8779 - val_loss: 0.4390 - val_accuracy: 0.8448\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3415 - accuracy: 0.8791 - val_loss: 0.3431 - val_accuracy: 0.8808\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3378 - accuracy: 0.8809 - val_loss: 0.3307 - val_accuracy: 0.8847\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3345 - accuracy: 0.8819 - val_loss: 0.3728 - val_accuracy: 0.8711\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3303 - accuracy: 0.8833 - val_loss: 0.3651 - val_accuracy: 0.8705\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3279 - accuracy: 0.8844 - val_loss: 0.3357 - val_accuracy: 0.8845\n",
            "\n",
            "Accuracy: 88.45%\n",
            "\n",
            "learning rate: 7.5e-04\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7390 - accuracy: 0.7392 - val_loss: 0.6433 - val_accuracy: 0.7696\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5933 - accuracy: 0.7889 - val_loss: 0.5644 - val_accuracy: 0.7984\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5425 - accuracy: 0.8076 - val_loss: 0.5214 - val_accuracy: 0.8183\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5021 - accuracy: 0.8228 - val_loss: 0.5014 - val_accuracy: 0.8202\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4702 - accuracy: 0.8335 - val_loss: 0.4565 - val_accuracy: 0.8373\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4454 - accuracy: 0.8420 - val_loss: 0.4596 - val_accuracy: 0.8388\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4260 - accuracy: 0.8495 - val_loss: 0.4285 - val_accuracy: 0.8461\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4115 - accuracy: 0.8549 - val_loss: 0.4202 - val_accuracy: 0.8481\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3984 - accuracy: 0.8595 - val_loss: 0.4078 - val_accuracy: 0.8538\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3881 - accuracy: 0.8631 - val_loss: 0.3905 - val_accuracy: 0.8627\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3796 - accuracy: 0.8663 - val_loss: 0.3793 - val_accuracy: 0.8659\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3729 - accuracy: 0.8684 - val_loss: 0.3731 - val_accuracy: 0.8675\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3657 - accuracy: 0.8706 - val_loss: 0.3880 - val_accuracy: 0.8636\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3598 - accuracy: 0.8730 - val_loss: 0.3733 - val_accuracy: 0.8677\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3553 - accuracy: 0.8748 - val_loss: 0.3783 - val_accuracy: 0.8672\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3505 - accuracy: 0.8767 - val_loss: 0.3580 - val_accuracy: 0.8755\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3463 - accuracy: 0.8779 - val_loss: 0.3548 - val_accuracy: 0.8748\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3429 - accuracy: 0.8794 - val_loss: 0.3820 - val_accuracy: 0.8642\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3399 - accuracy: 0.8806 - val_loss: 0.3753 - val_accuracy: 0.8722\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3371 - accuracy: 0.8817 - val_loss: 0.3811 - val_accuracy: 0.8636\n",
            "\n",
            "Accuracy: 86.36%\n",
            "\n",
            "learning rate: 1.2e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.9969 - accuracy: 0.6484 - val_loss: 0.7364 - val_accuracy: 0.7369\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6921 - accuracy: 0.7560 - val_loss: 0.6646 - val_accuracy: 0.7691\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6471 - accuracy: 0.7744 - val_loss: 0.6388 - val_accuracy: 0.7765\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.6223 - accuracy: 0.7813 - val_loss: 0.6155 - val_accuracy: 0.7802\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.6022 - accuracy: 0.7870 - val_loss: 0.5958 - val_accuracy: 0.7876\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.5856 - accuracy: 0.7925 - val_loss: 0.5819 - val_accuracy: 0.7933\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.5717 - accuracy: 0.7972 - val_loss: 0.5822 - val_accuracy: 0.7933\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5598 - accuracy: 0.8014 - val_loss: 0.5529 - val_accuracy: 0.8030\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5491 - accuracy: 0.8054 - val_loss: 0.5511 - val_accuracy: 0.8038\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5396 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.8094\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5308 - accuracy: 0.8124 - val_loss: 0.5292 - val_accuracy: 0.8129\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5230 - accuracy: 0.8157 - val_loss: 0.5228 - val_accuracy: 0.8173\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5159 - accuracy: 0.8184 - val_loss: 0.5199 - val_accuracy: 0.8154\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5094 - accuracy: 0.8207 - val_loss: 0.5132 - val_accuracy: 0.8202\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.5033 - accuracy: 0.8231 - val_loss: 0.5143 - val_accuracy: 0.8185\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4971 - accuracy: 0.8255 - val_loss: 0.5005 - val_accuracy: 0.8241\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4915 - accuracy: 0.8272 - val_loss: 0.4973 - val_accuracy: 0.8232\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4863 - accuracy: 0.8293 - val_loss: 0.4859 - val_accuracy: 0.8280\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4809 - accuracy: 0.8308 - val_loss: 0.4853 - val_accuracy: 0.8299\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4757 - accuracy: 0.8326 - val_loss: 0.4788 - val_accuracy: 0.8311\n",
            "\n",
            "Accuracy: 83.11%\n",
            "\n",
            "learning rate: 9.8e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 6\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.9401 - accuracy: 0.6542 - val_loss: 0.8528 - val_accuracy: 0.6968\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8068 - accuracy: 0.7087 - val_loss: 0.7956 - val_accuracy: 0.7185\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7865 - accuracy: 0.7179 - val_loss: 0.7845 - val_accuracy: 0.7135\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7811 - accuracy: 0.7209 - val_loss: 0.8327 - val_accuracy: 0.7153\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7747 - accuracy: 0.7237 - val_loss: 0.7800 - val_accuracy: 0.7215\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7664 - accuracy: 0.7269 - val_loss: 0.7905 - val_accuracy: 0.7194\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7548 - accuracy: 0.7313 - val_loss: 0.7710 - val_accuracy: 0.7211\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7501 - accuracy: 0.7337 - val_loss: 0.9221 - val_accuracy: 0.6600\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7493 - accuracy: 0.7347 - val_loss: 0.7537 - val_accuracy: 0.7351\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7499 - accuracy: 0.7341 - val_loss: 0.8495 - val_accuracy: 0.6982\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7513 - accuracy: 0.7352 - val_loss: 0.7406 - val_accuracy: 0.7374\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7485 - accuracy: 0.7364 - val_loss: 0.7960 - val_accuracy: 0.7256\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7481 - accuracy: 0.7362 - val_loss: 0.7749 - val_accuracy: 0.7320\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7491 - accuracy: 0.7360 - val_loss: 0.9566 - val_accuracy: 0.6554\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7473 - accuracy: 0.7369 - val_loss: 0.7824 - val_accuracy: 0.7288\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7479 - accuracy: 0.7376 - val_loss: 0.7589 - val_accuracy: 0.7340\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7478 - accuracy: 0.7370 - val_loss: 0.7625 - val_accuracy: 0.7314\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7481 - accuracy: 0.7369 - val_loss: 0.7253 - val_accuracy: 0.7429\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7482 - accuracy: 0.7381 - val_loss: 0.7946 - val_accuracy: 0.7194\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7470 - accuracy: 0.7381 - val_loss: 0.7260 - val_accuracy: 0.7470\n",
            "\n",
            "Accuracy: 74.70%\n",
            "\n",
            "learning rate: 7.0e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.7468 - accuracy: 0.7304 - val_loss: 0.6852 - val_accuracy: 0.7523\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5875 - accuracy: 0.7898 - val_loss: 0.5753 - val_accuracy: 0.7950\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5310 - accuracy: 0.8114 - val_loss: 0.5405 - val_accuracy: 0.8071\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4860 - accuracy: 0.8281 - val_loss: 0.4773 - val_accuracy: 0.8319\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4513 - accuracy: 0.8398 - val_loss: 0.4361 - val_accuracy: 0.8455\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4265 - accuracy: 0.8482 - val_loss: 0.4197 - val_accuracy: 0.8524\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4076 - accuracy: 0.8550 - val_loss: 0.4340 - val_accuracy: 0.8419\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3925 - accuracy: 0.8602 - val_loss: 0.3973 - val_accuracy: 0.8590\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3809 - accuracy: 0.8643 - val_loss: 0.3943 - val_accuracy: 0.8606\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3710 - accuracy: 0.8677 - val_loss: 0.3747 - val_accuracy: 0.8667\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3626 - accuracy: 0.8715 - val_loss: 0.3643 - val_accuracy: 0.8721\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3560 - accuracy: 0.8737 - val_loss: 0.3897 - val_accuracy: 0.8602\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3496 - accuracy: 0.8763 - val_loss: 0.3827 - val_accuracy: 0.8657\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3449 - accuracy: 0.8773 - val_loss: 0.3505 - val_accuracy: 0.8758\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3404 - accuracy: 0.8789 - val_loss: 0.3528 - val_accuracy: 0.8751\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3369 - accuracy: 0.8808 - val_loss: 0.3329 - val_accuracy: 0.8827\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3348 - accuracy: 0.8817 - val_loss: 0.3513 - val_accuracy: 0.8762\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3322 - accuracy: 0.8829 - val_loss: 0.3292 - val_accuracy: 0.8839\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3299 - accuracy: 0.8837 - val_loss: 0.3453 - val_accuracy: 0.8791\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3282 - accuracy: 0.8846 - val_loss: 0.3399 - val_accuracy: 0.8829\n",
            "\n",
            "Accuracy: 88.29%\n",
            "\n",
            "learning rate: 1.0e-02\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 35\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7140 - accuracy: 0.7509 - val_loss: 0.6502 - val_accuracy: 0.7698\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6212 - accuracy: 0.7817 - val_loss: 0.6300 - val_accuracy: 0.7722\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5979 - accuracy: 0.7901 - val_loss: 0.5894 - val_accuracy: 0.7957\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5852 - accuracy: 0.7955 - val_loss: 0.5832 - val_accuracy: 0.7986\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5759 - accuracy: 0.7990 - val_loss: 0.5639 - val_accuracy: 0.8003\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5653 - accuracy: 0.8030 - val_loss: 0.5952 - val_accuracy: 0.7923\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5587 - accuracy: 0.8053 - val_loss: 0.5557 - val_accuracy: 0.8070\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5540 - accuracy: 0.8081 - val_loss: 0.5771 - val_accuracy: 0.8034\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5497 - accuracy: 0.8094 - val_loss: 0.5826 - val_accuracy: 0.7965\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5472 - accuracy: 0.8106 - val_loss: 0.5726 - val_accuracy: 0.8005\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5448 - accuracy: 0.8113 - val_loss: 0.5623 - val_accuracy: 0.8074\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5433 - accuracy: 0.8119 - val_loss: 0.5728 - val_accuracy: 0.7998\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5416 - accuracy: 0.8127 - val_loss: 0.5564 - val_accuracy: 0.8076\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5415 - accuracy: 0.8138 - val_loss: 0.5529 - val_accuracy: 0.8106\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5412 - accuracy: 0.8139 - val_loss: 0.5474 - val_accuracy: 0.8135\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5415 - accuracy: 0.8145 - val_loss: 0.5695 - val_accuracy: 0.8033\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5421 - accuracy: 0.8138 - val_loss: 0.5581 - val_accuracy: 0.8097\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5423 - accuracy: 0.8142 - val_loss: 0.5859 - val_accuracy: 0.7990\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5425 - accuracy: 0.8145 - val_loss: 0.5564 - val_accuracy: 0.8084\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5429 - accuracy: 0.8149 - val_loss: 0.5727 - val_accuracy: 0.8039\n",
            "\n",
            "Accuracy: 80.39%\n",
            "\n",
            "learning rate: 1.9e-04\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 63\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.3311 - accuracy: 0.5358 - val_loss: 1.0510 - val_accuracy: 0.6232\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.9577 - accuracy: 0.6654 - val_loss: 0.8903 - val_accuracy: 0.6951\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8471 - accuracy: 0.7097 - val_loss: 0.8171 - val_accuracy: 0.7189\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7920 - accuracy: 0.7290 - val_loss: 0.7769 - val_accuracy: 0.7298\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7607 - accuracy: 0.7395 - val_loss: 0.7525 - val_accuracy: 0.7412\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7405 - accuracy: 0.7470 - val_loss: 0.7355 - val_accuracy: 0.7476\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7256 - accuracy: 0.7527 - val_loss: 0.7222 - val_accuracy: 0.7544\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7131 - accuracy: 0.7569 - val_loss: 0.7094 - val_accuracy: 0.7570\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7022 - accuracy: 0.7603 - val_loss: 0.6996 - val_accuracy: 0.7606\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6930 - accuracy: 0.7630 - val_loss: 0.6914 - val_accuracy: 0.7630\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6851 - accuracy: 0.7657 - val_loss: 0.6836 - val_accuracy: 0.7677\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6783 - accuracy: 0.7680 - val_loss: 0.6774 - val_accuracy: 0.7683\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6725 - accuracy: 0.7696 - val_loss: 0.6720 - val_accuracy: 0.7699\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6674 - accuracy: 0.7710 - val_loss: 0.6674 - val_accuracy: 0.7713\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6628 - accuracy: 0.7725 - val_loss: 0.6626 - val_accuracy: 0.7729\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6586 - accuracy: 0.7737 - val_loss: 0.6589 - val_accuracy: 0.7738\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6547 - accuracy: 0.7747 - val_loss: 0.6551 - val_accuracy: 0.7744\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6510 - accuracy: 0.7754 - val_loss: 0.6513 - val_accuracy: 0.7749\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6476 - accuracy: 0.7762 - val_loss: 0.6480 - val_accuracy: 0.7763\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6445 - accuracy: 0.7772 - val_loss: 0.6452 - val_accuracy: 0.7771\n",
            "\n",
            "Accuracy: 77.71%\n",
            "\n",
            "learning rate: 2.3e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 36\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7111 - accuracy: 0.7432 - val_loss: 0.6197 - val_accuracy: 0.7817\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5646 - accuracy: 0.7988 - val_loss: 0.5851 - val_accuracy: 0.7931\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5124 - accuracy: 0.8171 - val_loss: 0.5105 - val_accuracy: 0.8179\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4780 - accuracy: 0.8299 - val_loss: 0.4912 - val_accuracy: 0.8238\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4545 - accuracy: 0.8391 - val_loss: 0.4559 - val_accuracy: 0.8407\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4371 - accuracy: 0.8456 - val_loss: 0.4662 - val_accuracy: 0.8321\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4246 - accuracy: 0.8502 - val_loss: 0.4587 - val_accuracy: 0.8373\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4184 - accuracy: 0.8533 - val_loss: 0.4508 - val_accuracy: 0.8404\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4122 - accuracy: 0.8563 - val_loss: 0.4430 - val_accuracy: 0.8491\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4097 - accuracy: 0.8576 - val_loss: 0.5091 - val_accuracy: 0.8280\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4055 - accuracy: 0.8586 - val_loss: 0.4250 - val_accuracy: 0.8519\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4045 - accuracy: 0.8597 - val_loss: 0.4014 - val_accuracy: 0.8590\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4023 - accuracy: 0.8601 - val_loss: 0.4972 - val_accuracy: 0.8311\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4032 - accuracy: 0.8602 - val_loss: 0.4362 - val_accuracy: 0.8478\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4049 - accuracy: 0.8605 - val_loss: 0.4493 - val_accuracy: 0.8482\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4076 - accuracy: 0.8604 - val_loss: 0.4557 - val_accuracy: 0.8415\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4105 - accuracy: 0.8599 - val_loss: 0.4330 - val_accuracy: 0.8508\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4169 - accuracy: 0.8592 - val_loss: 0.4610 - val_accuracy: 0.8474\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4246 - accuracy: 0.8590 - val_loss: 0.4017 - val_accuracy: 0.8613\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4582 - accuracy: 0.8580 - val_loss: 0.4590 - val_accuracy: 0.8491\n",
            "\n",
            "Accuracy: 84.91%\n",
            "\n",
            "learning rate: 5.4e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7638 - accuracy: 0.7276 - val_loss: 0.6639 - val_accuracy: 0.7639\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5919 - accuracy: 0.7892 - val_loss: 0.5783 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.5393 - accuracy: 0.8077 - val_loss: 0.5429 - val_accuracy: 0.8042\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.5030 - accuracy: 0.8214 - val_loss: 0.4898 - val_accuracy: 0.8239\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4750 - accuracy: 0.8324 - val_loss: 0.4814 - val_accuracy: 0.8295\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4529 - accuracy: 0.8397 - val_loss: 0.4530 - val_accuracy: 0.8380\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4340 - accuracy: 0.8461 - val_loss: 0.4553 - val_accuracy: 0.8395\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4169 - accuracy: 0.8517 - val_loss: 0.4263 - val_accuracy: 0.8506\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4025 - accuracy: 0.8574 - val_loss: 0.4109 - val_accuracy: 0.8551\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3911 - accuracy: 0.8610 - val_loss: 0.3970 - val_accuracy: 0.8619\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3818 - accuracy: 0.8649 - val_loss: 0.4466 - val_accuracy: 0.8396\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3734 - accuracy: 0.8675 - val_loss: 0.3740 - val_accuracy: 0.8691\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3666 - accuracy: 0.8703 - val_loss: 0.3751 - val_accuracy: 0.8664\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3602 - accuracy: 0.8720 - val_loss: 0.3735 - val_accuracy: 0.8672\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3543 - accuracy: 0.8747 - val_loss: 0.3618 - val_accuracy: 0.8709\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3493 - accuracy: 0.8761 - val_loss: 0.3628 - val_accuracy: 0.8720\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3456 - accuracy: 0.8776 - val_loss: 0.3780 - val_accuracy: 0.8719\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3413 - accuracy: 0.8793 - val_loss: 0.3647 - val_accuracy: 0.8701\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3374 - accuracy: 0.8806 - val_loss: 0.3982 - val_accuracy: 0.8550\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3347 - accuracy: 0.8820 - val_loss: 0.3575 - val_accuracy: 0.8756\n",
            "\n",
            "Accuracy: 87.56%\n",
            "\n",
            "learning rate: 1.2e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.7046 - accuracy: 0.7446 - val_loss: 0.6107 - val_accuracy: 0.7778\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5303 - accuracy: 0.8108 - val_loss: 0.5089 - val_accuracy: 0.8176\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4669 - accuracy: 0.8330 - val_loss: 0.5147 - val_accuracy: 0.8147\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4265 - accuracy: 0.8479 - val_loss: 0.4345 - val_accuracy: 0.8457\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4005 - accuracy: 0.8582 - val_loss: 0.4059 - val_accuracy: 0.8528\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3848 - accuracy: 0.8636 - val_loss: 0.3686 - val_accuracy: 0.8700\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3732 - accuracy: 0.8677 - val_loss: 0.3820 - val_accuracy: 0.8653\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3642 - accuracy: 0.8711 - val_loss: 0.3804 - val_accuracy: 0.8651\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3586 - accuracy: 0.8736 - val_loss: 0.3511 - val_accuracy: 0.8764\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3554 - accuracy: 0.8750 - val_loss: 0.3791 - val_accuracy: 0.8666\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3546 - accuracy: 0.8757 - val_loss: 0.3734 - val_accuracy: 0.8697\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3553 - accuracy: 0.8773 - val_loss: 0.4101 - val_accuracy: 0.8585\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3517 - accuracy: 0.8782 - val_loss: 0.3597 - val_accuracy: 0.8749\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3529 - accuracy: 0.8784 - val_loss: 0.3740 - val_accuracy: 0.8714\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3568 - accuracy: 0.8774 - val_loss: 0.3638 - val_accuracy: 0.8749\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3601 - accuracy: 0.8766 - val_loss: 0.3997 - val_accuracy: 0.8735\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3691 - accuracy: 0.8753 - val_loss: 0.4364 - val_accuracy: 0.8644\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3690 - accuracy: 0.8739 - val_loss: 0.4049 - val_accuracy: 0.8659\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3788 - accuracy: 0.8724 - val_loss: 0.4052 - val_accuracy: 0.8629\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3842 - accuracy: 0.8706 - val_loss: 0.3775 - val_accuracy: 0.8715\n",
            "\n",
            "Accuracy: 87.15%\n",
            "\n",
            "learning rate: 3.3e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 47\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.8887 - accuracy: 0.6764 - val_loss: 0.7105 - val_accuracy: 0.7363\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6560 - accuracy: 0.7667 - val_loss: 0.6356 - val_accuracy: 0.7740\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6105 - accuracy: 0.7831 - val_loss: 0.5934 - val_accuracy: 0.7864\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.5846 - accuracy: 0.7917 - val_loss: 0.5803 - val_accuracy: 0.7926\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5670 - accuracy: 0.7973 - val_loss: 0.5627 - val_accuracy: 0.7979\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5522 - accuracy: 0.8018 - val_loss: 0.5427 - val_accuracy: 0.8059\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5395 - accuracy: 0.8065 - val_loss: 0.5336 - val_accuracy: 0.8093\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5284 - accuracy: 0.8108 - val_loss: 0.5207 - val_accuracy: 0.8146\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5174 - accuracy: 0.8152 - val_loss: 0.5136 - val_accuracy: 0.8189\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.5076 - accuracy: 0.8201 - val_loss: 0.5179 - val_accuracy: 0.8141\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4977 - accuracy: 0.8241 - val_loss: 0.5041 - val_accuracy: 0.8226\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4878 - accuracy: 0.8281 - val_loss: 0.4880 - val_accuracy: 0.8285\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4779 - accuracy: 0.8317 - val_loss: 0.4715 - val_accuracy: 0.8331\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4692 - accuracy: 0.8352 - val_loss: 0.4710 - val_accuracy: 0.8334\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4604 - accuracy: 0.8377 - val_loss: 0.4562 - val_accuracy: 0.8403\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4516 - accuracy: 0.8415 - val_loss: 0.4623 - val_accuracy: 0.8391\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4442 - accuracy: 0.8439 - val_loss: 0.4555 - val_accuracy: 0.8394\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4374 - accuracy: 0.8465 - val_loss: 0.4458 - val_accuracy: 0.8444\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4316 - accuracy: 0.8491 - val_loss: 0.4358 - val_accuracy: 0.8458\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.4263 - accuracy: 0.8507 - val_loss: 0.4359 - val_accuracy: 0.8483\n",
            "\n",
            "Accuracy: 84.83%\n",
            "\n",
            "learning rate: 2.0e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 40\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8431 - accuracy: 0.7084 - val_loss: 0.7052 - val_accuracy: 0.7590\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6787 - accuracy: 0.7654 - val_loss: 0.6607 - val_accuracy: 0.7712\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6487 - accuracy: 0.7746 - val_loss: 0.6418 - val_accuracy: 0.7745\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6323 - accuracy: 0.7791 - val_loss: 0.6273 - val_accuracy: 0.7805\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6212 - accuracy: 0.7824 - val_loss: 0.6198 - val_accuracy: 0.7825\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6111 - accuracy: 0.7858 - val_loss: 0.6087 - val_accuracy: 0.7857\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6028 - accuracy: 0.7885 - val_loss: 0.6070 - val_accuracy: 0.7877\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5960 - accuracy: 0.7912 - val_loss: 0.5956 - val_accuracy: 0.7905\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5899 - accuracy: 0.7936 - val_loss: 0.6034 - val_accuracy: 0.7898\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5838 - accuracy: 0.7966 - val_loss: 0.5827 - val_accuracy: 0.7973\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5777 - accuracy: 0.7986 - val_loss: 0.5872 - val_accuracy: 0.7925\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5725 - accuracy: 0.8005 - val_loss: 0.5713 - val_accuracy: 0.8011\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5681 - accuracy: 0.8018 - val_loss: 0.5690 - val_accuracy: 0.8011\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5638 - accuracy: 0.8034 - val_loss: 0.5669 - val_accuracy: 0.8025\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5598 - accuracy: 0.8046 - val_loss: 0.5617 - val_accuracy: 0.8053\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5563 - accuracy: 0.8058 - val_loss: 0.5607 - val_accuracy: 0.8066\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5533 - accuracy: 0.8072 - val_loss: 0.5590 - val_accuracy: 0.8064\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5500 - accuracy: 0.8083 - val_loss: 0.5571 - val_accuracy: 0.8071\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5473 - accuracy: 0.8097 - val_loss: 0.5504 - val_accuracy: 0.8088\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5449 - accuracy: 0.8104 - val_loss: 0.5537 - val_accuracy: 0.8082\n",
            "\n",
            "Accuracy: 80.82%\n",
            "\n",
            "learning rate: 8.6e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.7190 - accuracy: 0.7400 - val_loss: 0.6282 - val_accuracy: 0.7732\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.5610 - accuracy: 0.8003 - val_loss: 0.5246 - val_accuracy: 0.8147\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4974 - accuracy: 0.8230 - val_loss: 0.4933 - val_accuracy: 0.8259\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4536 - accuracy: 0.8381 - val_loss: 0.4717 - val_accuracy: 0.8317\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4227 - accuracy: 0.8491 - val_loss: 0.4424 - val_accuracy: 0.8377\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.4016 - accuracy: 0.8574 - val_loss: 0.4165 - val_accuracy: 0.8557\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3857 - accuracy: 0.8635 - val_loss: 0.4123 - val_accuracy: 0.8522\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 9s 2ms/step - loss: 0.3744 - accuracy: 0.8677 - val_loss: 0.4076 - val_accuracy: 0.8548\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3652 - accuracy: 0.8712 - val_loss: 0.3863 - val_accuracy: 0.8649\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.3569 - accuracy: 0.8748 - val_loss: 0.3748 - val_accuracy: 0.8696\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3504 - accuracy: 0.8770 - val_loss: 0.3727 - val_accuracy: 0.8676\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3451 - accuracy: 0.8789 - val_loss: 0.3506 - val_accuracy: 0.8797\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3405 - accuracy: 0.8808 - val_loss: 0.3518 - val_accuracy: 0.8810\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3368 - accuracy: 0.8821 - val_loss: 0.3494 - val_accuracy: 0.8777\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3330 - accuracy: 0.8835 - val_loss: 0.3612 - val_accuracy: 0.8752\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3299 - accuracy: 0.8850 - val_loss: 0.3596 - val_accuracy: 0.8759\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3275 - accuracy: 0.8857 - val_loss: 0.3477 - val_accuracy: 0.8805\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3269 - accuracy: 0.8863 - val_loss: 0.3417 - val_accuracy: 0.8854\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3240 - accuracy: 0.8874 - val_loss: 0.3370 - val_accuracy: 0.8840\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3222 - accuracy: 0.8878 - val_loss: 0.3232 - val_accuracy: 0.8896\n",
            "\n",
            "Accuracy: 88.96%\n",
            "\n",
            "learning rate: 1.6e-03\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 63\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6740 - accuracy: 0.7580 - val_loss: 0.6229 - val_accuracy: 0.7707\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5221 - accuracy: 0.8131 - val_loss: 0.4984 - val_accuracy: 0.8203\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4615 - accuracy: 0.8350 - val_loss: 0.4947 - val_accuracy: 0.8298\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4288 - accuracy: 0.8476 - val_loss: 0.4375 - val_accuracy: 0.8457\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4092 - accuracy: 0.8544 - val_loss: 0.4431 - val_accuracy: 0.8403\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3971 - accuracy: 0.8585 - val_loss: 0.4162 - val_accuracy: 0.8533\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3878 - accuracy: 0.8625 - val_loss: 0.4086 - val_accuracy: 0.8542\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3816 - accuracy: 0.8652 - val_loss: 0.3826 - val_accuracy: 0.8658\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3775 - accuracy: 0.8673 - val_loss: 0.4234 - val_accuracy: 0.8513\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3748 - accuracy: 0.8688 - val_loss: 0.3745 - val_accuracy: 0.8712\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3733 - accuracy: 0.8697 - val_loss: 0.3997 - val_accuracy: 0.8664\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3727 - accuracy: 0.8704 - val_loss: 0.4278 - val_accuracy: 0.8551\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3743 - accuracy: 0.8704 - val_loss: 0.3846 - val_accuracy: 0.8747\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3768 - accuracy: 0.8697 - val_loss: 0.4011 - val_accuracy: 0.8611\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3806 - accuracy: 0.8687 - val_loss: 0.4168 - val_accuracy: 0.8636\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3850 - accuracy: 0.8679 - val_loss: 0.4697 - val_accuracy: 0.8504\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3884 - accuracy: 0.8665 - val_loss: 0.4446 - val_accuracy: 0.8566\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3924 - accuracy: 0.8660 - val_loss: 0.4422 - val_accuracy: 0.8600\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3957 - accuracy: 0.8652 - val_loss: 0.4424 - val_accuracy: 0.8579\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4004 - accuracy: 0.8642 - val_loss: 0.5484 - val_accuracy: 0.8323\n",
            "\n",
            "Accuracy: 83.23%\n",
            "\n",
            "learning rate: 8.0e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7235 - accuracy: 0.7411 - val_loss: 0.6167 - val_accuracy: 0.7790\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5670 - accuracy: 0.7973 - val_loss: 0.5730 - val_accuracy: 0.7991\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5084 - accuracy: 0.8184 - val_loss: 0.4986 - val_accuracy: 0.8221\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4644 - accuracy: 0.8334 - val_loss: 0.4669 - val_accuracy: 0.8360\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4331 - accuracy: 0.8455 - val_loss: 0.4463 - val_accuracy: 0.8406\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4103 - accuracy: 0.8538 - val_loss: 0.4149 - val_accuracy: 0.8542\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3932 - accuracy: 0.8604 - val_loss: 0.4060 - val_accuracy: 0.8553\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3798 - accuracy: 0.8650 - val_loss: 0.4090 - val_accuracy: 0.8541\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3702 - accuracy: 0.8687 - val_loss: 0.3819 - val_accuracy: 0.8622\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3612 - accuracy: 0.8725 - val_loss: 0.3613 - val_accuracy: 0.8729\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3549 - accuracy: 0.8746 - val_loss: 0.3769 - val_accuracy: 0.8687\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3501 - accuracy: 0.8764 - val_loss: 0.3738 - val_accuracy: 0.8673\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3448 - accuracy: 0.8785 - val_loss: 0.3583 - val_accuracy: 0.8730\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3401 - accuracy: 0.8805 - val_loss: 0.3545 - val_accuracy: 0.8743\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3372 - accuracy: 0.8814 - val_loss: 0.3734 - val_accuracy: 0.8711\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3337 - accuracy: 0.8833 - val_loss: 0.3493 - val_accuracy: 0.8776\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3308 - accuracy: 0.8842 - val_loss: 0.3735 - val_accuracy: 0.8692\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 9s 2ms/step - loss: 0.3288 - accuracy: 0.8849 - val_loss: 0.3685 - val_accuracy: 0.8741\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3279 - accuracy: 0.8852 - val_loss: 0.3328 - val_accuracy: 0.8826\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3267 - accuracy: 0.8856 - val_loss: 0.3368 - val_accuracy: 0.8834\n",
            "\n",
            "Accuracy: 88.34%\n",
            "\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 61\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.5689 - accuracy: 0.1079 - val_loss: 2.5347 - val_accuracy: 0.1223\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.4998 - accuracy: 0.1334 - val_loss: 2.4665 - val_accuracy: 0.1438\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 2.4329 - accuracy: 0.1493 - val_loss: 2.4006 - val_accuracy: 0.1534\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.3687 - accuracy: 0.1628 - val_loss: 2.3379 - val_accuracy: 0.1778\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.3081 - accuracy: 0.1980 - val_loss: 2.2791 - val_accuracy: 0.2238\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.2514 - accuracy: 0.2422 - val_loss: 2.2249 - val_accuracy: 0.2670\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.2002 - accuracy: 0.3007 - val_loss: 2.1766 - val_accuracy: 0.3338\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.1551 - accuracy: 0.3432 - val_loss: 2.1345 - val_accuracy: 0.3560\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.1160 - accuracy: 0.3658 - val_loss: 2.0983 - val_accuracy: 0.3758\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.0823 - accuracy: 0.3808 - val_loss: 2.0666 - val_accuracy: 0.3879\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.0523 - accuracy: 0.3913 - val_loss: 2.0381 - val_accuracy: 0.3965\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 2.0250 - accuracy: 0.3991 - val_loss: 2.0118 - val_accuracy: 0.4025\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.9996 - accuracy: 0.4078 - val_loss: 1.9871 - val_accuracy: 0.4119\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.9754 - accuracy: 0.4214 - val_loss: 1.9633 - val_accuracy: 0.4299\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.9520 - accuracy: 0.4365 - val_loss: 1.9402 - val_accuracy: 0.4379\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.9293 - accuracy: 0.4417 - val_loss: 1.9177 - val_accuracy: 0.4445\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.9070 - accuracy: 0.4454 - val_loss: 1.8955 - val_accuracy: 0.4410\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.8850 - accuracy: 0.4393 - val_loss: 1.8737 - val_accuracy: 0.4350\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.8634 - accuracy: 0.4353 - val_loss: 1.8523 - val_accuracy: 0.4327\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.8421 - accuracy: 0.4354 - val_loss: 1.8311 - val_accuracy: 0.4364\n",
            "\n",
            "Accuracy: 43.64%\n",
            "\n",
            "learning rate: 1.0e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 5\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4299 - accuracy: 0.4434 - val_loss: 1.1175 - val_accuracy: 0.5946\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 1.0427 - accuracy: 0.6116 - val_loss: 1.0196 - val_accuracy: 0.6218\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9836 - accuracy: 0.6288 - val_loss: 0.9826 - val_accuracy: 0.6293\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9647 - accuracy: 0.6327 - val_loss: 0.9625 - val_accuracy: 0.6371\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9478 - accuracy: 0.6430 - val_loss: 0.9438 - val_accuracy: 0.6477\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9299 - accuracy: 0.6517 - val_loss: 0.9201 - val_accuracy: 0.6560\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9064 - accuracy: 0.6601 - val_loss: 0.8941 - val_accuracy: 0.6679\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8819 - accuracy: 0.6668 - val_loss: 0.8732 - val_accuracy: 0.6663\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8683 - accuracy: 0.6690 - val_loss: 0.8624 - val_accuracy: 0.6661\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8589 - accuracy: 0.6706 - val_loss: 0.8629 - val_accuracy: 0.6763\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8497 - accuracy: 0.6757 - val_loss: 0.8471 - val_accuracy: 0.6775\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8323 - accuracy: 0.6856 - val_loss: 0.8253 - val_accuracy: 0.6903\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8170 - accuracy: 0.6934 - val_loss: 0.8177 - val_accuracy: 0.6975\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8080 - accuracy: 0.6994 - val_loss: 0.8116 - val_accuracy: 0.7020\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8014 - accuracy: 0.7023 - val_loss: 0.8099 - val_accuracy: 0.6973\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7965 - accuracy: 0.7050 - val_loss: 0.8025 - val_accuracy: 0.7024\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7923 - accuracy: 0.7074 - val_loss: 0.7881 - val_accuracy: 0.7123\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7883 - accuracy: 0.7099 - val_loss: 0.7886 - val_accuracy: 0.7122\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7844 - accuracy: 0.7124 - val_loss: 0.7842 - val_accuracy: 0.7144\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7800 - accuracy: 0.7145 - val_loss: 0.7799 - val_accuracy: 0.7157\n",
            "\n",
            "Accuracy: 71.57%\n",
            "\n",
            "learning rate: 9.9e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 36\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7157 - accuracy: 0.7455 - val_loss: 0.6307 - val_accuracy: 0.7835\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 8s 2ms/step - loss: 0.6276 - accuracy: 0.7860 - val_loss: 0.7240 - val_accuracy: 0.7538\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6554 - accuracy: 0.7890 - val_loss: 0.6911 - val_accuracy: 0.7720\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6476 - accuracy: 0.7925 - val_loss: 0.7718 - val_accuracy: 0.7941\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6492 - accuracy: 0.7924 - val_loss: 0.5832 - val_accuracy: 0.8053\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6709 - accuracy: 0.7922 - val_loss: 0.7661 - val_accuracy: 0.7744\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6648 - accuracy: 0.7918 - val_loss: 0.8321 - val_accuracy: 0.7403\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6693 - accuracy: 0.7911 - val_loss: 0.8507 - val_accuracy: 0.7729\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7309 - accuracy: 0.7887 - val_loss: 0.7107 - val_accuracy: 0.7956\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6997 - accuracy: 0.7896 - val_loss: 0.7553 - val_accuracy: 0.7944\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8821 - accuracy: 0.7861 - val_loss: 0.9436 - val_accuracy: 0.6872\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7690 - accuracy: 0.7890 - val_loss: 0.7294 - val_accuracy: 0.7877\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7177 - accuracy: 0.7857 - val_loss: 0.7579 - val_accuracy: 0.7537\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7437 - accuracy: 0.7822 - val_loss: 0.8612 - val_accuracy: 0.7872\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8214 - accuracy: 0.7739 - val_loss: 0.9635 - val_accuracy: 0.7127\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.9005 - accuracy: 0.7687 - val_loss: 1.1480 - val_accuracy: 0.7567\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8305 - accuracy: 0.7630 - val_loss: 2.2754 - val_accuracy: 0.6967\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.9773 - accuracy: 0.7556 - val_loss: 1.2180 - val_accuracy: 0.7599\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.0225 - accuracy: 0.7517 - val_loss: 3.3788 - val_accuracy: 0.7115\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4242 - accuracy: 0.7358 - val_loss: 1.2436 - val_accuracy: 0.7499\n",
            "\n",
            "Accuracy: 74.99%\n",
            "\n",
            "learning rate: 8.9e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 6\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.9190 - accuracy: 0.6766 - val_loss: 0.8228 - val_accuracy: 0.7192\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.8061 - accuracy: 0.7273 - val_loss: 0.8075 - val_accuracy: 0.7310\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7927 - accuracy: 0.7334 - val_loss: 0.7945 - val_accuracy: 0.7351\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7848 - accuracy: 0.7357 - val_loss: 0.7834 - val_accuracy: 0.7350\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7793 - accuracy: 0.7362 - val_loss: 0.7935 - val_accuracy: 0.7277\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7756 - accuracy: 0.7367 - val_loss: 0.7757 - val_accuracy: 0.7331\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7727 - accuracy: 0.7376 - val_loss: 0.7727 - val_accuracy: 0.7388\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7709 - accuracy: 0.7378 - val_loss: 0.7935 - val_accuracy: 0.7293\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7692 - accuracy: 0.7386 - val_loss: 0.7705 - val_accuracy: 0.7407\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7677 - accuracy: 0.7395 - val_loss: 0.7938 - val_accuracy: 0.7309\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7660 - accuracy: 0.7401 - val_loss: 0.7706 - val_accuracy: 0.7368\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7646 - accuracy: 0.7412 - val_loss: 0.7776 - val_accuracy: 0.7373\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 992us/step - loss: 0.7627 - accuracy: 0.7421 - val_loss: 0.7633 - val_accuracy: 0.7402\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7605 - accuracy: 0.7433 - val_loss: 0.7609 - val_accuracy: 0.7493\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7552 - accuracy: 0.7464 - val_loss: 0.7559 - val_accuracy: 0.7459\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 995us/step - loss: 0.7522 - accuracy: 0.7488 - val_loss: 0.7598 - val_accuracy: 0.7450\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7505 - accuracy: 0.7496 - val_loss: 0.7702 - val_accuracy: 0.7399\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7489 - accuracy: 0.7505 - val_loss: 0.7747 - val_accuracy: 0.7370\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.7478 - accuracy: 0.7511 - val_loss: 0.7532 - val_accuracy: 0.7493\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 996us/step - loss: 0.7467 - accuracy: 0.7518 - val_loss: 0.7421 - val_accuracy: 0.7521\n",
            "\n",
            "Accuracy: 75.21%\n",
            "\n",
            "learning rate: 1.0e-02\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6948 - accuracy: 0.7548 - val_loss: 0.6149 - val_accuracy: 0.7806\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.6015 - accuracy: 0.7875 - val_loss: 0.6001 - val_accuracy: 0.7902\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5756 - accuracy: 0.7974 - val_loss: 0.5749 - val_accuracy: 0.7978\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5619 - accuracy: 0.8033 - val_loss: 0.5998 - val_accuracy: 0.7907\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5510 - accuracy: 0.8082 - val_loss: 0.5831 - val_accuracy: 0.7960\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5438 - accuracy: 0.8114 - val_loss: 0.5726 - val_accuracy: 0.8037\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5383 - accuracy: 0.8141 - val_loss: 0.5785 - val_accuracy: 0.7973\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5353 - accuracy: 0.8152 - val_loss: 0.5699 - val_accuracy: 0.8005\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5315 - accuracy: 0.8161 - val_loss: 0.5397 - val_accuracy: 0.8126\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5293 - accuracy: 0.8175 - val_loss: 0.5401 - val_accuracy: 0.8222\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5265 - accuracy: 0.8179 - val_loss: 0.5347 - val_accuracy: 0.8156\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5249 - accuracy: 0.8199 - val_loss: 0.5524 - val_accuracy: 0.8080\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5233 - accuracy: 0.8209 - val_loss: 0.5423 - val_accuracy: 0.8179\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5220 - accuracy: 0.8212 - val_loss: 0.5396 - val_accuracy: 0.8157\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5215 - accuracy: 0.8225 - val_loss: 0.5748 - val_accuracy: 0.8090\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5188 - accuracy: 0.8240 - val_loss: 0.5627 - val_accuracy: 0.8090\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5174 - accuracy: 0.8250 - val_loss: 0.5207 - val_accuracy: 0.8250\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5176 - accuracy: 0.8257 - val_loss: 0.5414 - val_accuracy: 0.8139\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5166 - accuracy: 0.8258 - val_loss: 0.5590 - val_accuracy: 0.8058\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 4s 1ms/step - loss: 0.5152 - accuracy: 0.8259 - val_loss: 0.5660 - val_accuracy: 0.8115\n",
            "\n",
            "Accuracy: 81.15%\n",
            "\n",
            "learning rate: 3.7e-04\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 43\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.9225 - accuracy: 0.6747 - val_loss: 0.7162 - val_accuracy: 0.7463\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6772 - accuracy: 0.7625 - val_loss: 0.6558 - val_accuracy: 0.7693\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6381 - accuracy: 0.7754 - val_loss: 0.6256 - val_accuracy: 0.7791\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6151 - accuracy: 0.7822 - val_loss: 0.6058 - val_accuracy: 0.7840\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5979 - accuracy: 0.7870 - val_loss: 0.5916 - val_accuracy: 0.7893\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5836 - accuracy: 0.7915 - val_loss: 0.5799 - val_accuracy: 0.7913\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5711 - accuracy: 0.7957 - val_loss: 0.5726 - val_accuracy: 0.7941\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5600 - accuracy: 0.7996 - val_loss: 0.5631 - val_accuracy: 0.7979\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5497 - accuracy: 0.8039 - val_loss: 0.5610 - val_accuracy: 0.7992\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5409 - accuracy: 0.8078 - val_loss: 0.5446 - val_accuracy: 0.8052\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5330 - accuracy: 0.8111 - val_loss: 0.5318 - val_accuracy: 0.8106\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5262 - accuracy: 0.8140 - val_loss: 0.5240 - val_accuracy: 0.8150\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5201 - accuracy: 0.8170 - val_loss: 0.5186 - val_accuracy: 0.8186\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5143 - accuracy: 0.8198 - val_loss: 0.5150 - val_accuracy: 0.8193\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5093 - accuracy: 0.8216 - val_loss: 0.5110 - val_accuracy: 0.8215\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5039 - accuracy: 0.8236 - val_loss: 0.5060 - val_accuracy: 0.8225\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4989 - accuracy: 0.8254 - val_loss: 0.5039 - val_accuracy: 0.8255\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4946 - accuracy: 0.8273 - val_loss: 0.5072 - val_accuracy: 0.8219\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4902 - accuracy: 0.8284 - val_loss: 0.4969 - val_accuracy: 0.8273\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4863 - accuracy: 0.8300 - val_loss: 0.4851 - val_accuracy: 0.8295\n",
            "\n",
            "Accuracy: 82.95%\n",
            "\n",
            "learning rate: 1.4e-03\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 37\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7472 - accuracy: 0.7308 - val_loss: 0.6567 - val_accuracy: 0.7652\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6000 - accuracy: 0.7860 - val_loss: 0.5839 - val_accuracy: 0.7952\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5462 - accuracy: 0.8066 - val_loss: 0.5342 - val_accuracy: 0.8108\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.5123 - accuracy: 0.8189 - val_loss: 0.5235 - val_accuracy: 0.8124\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4875 - accuracy: 0.8273 - val_loss: 0.4950 - val_accuracy: 0.8251\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4657 - accuracy: 0.8351 - val_loss: 0.4837 - val_accuracy: 0.8295\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4480 - accuracy: 0.8412 - val_loss: 0.4386 - val_accuracy: 0.8465\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4342 - accuracy: 0.8473 - val_loss: 0.4283 - val_accuracy: 0.8486\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4241 - accuracy: 0.8517 - val_loss: 0.4250 - val_accuracy: 0.8528\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4161 - accuracy: 0.8544 - val_loss: 0.4259 - val_accuracy: 0.8524\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4096 - accuracy: 0.8569 - val_loss: 0.4325 - val_accuracy: 0.8474\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4050 - accuracy: 0.8586 - val_loss: 0.4473 - val_accuracy: 0.8451\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.4004 - accuracy: 0.8603 - val_loss: 0.4001 - val_accuracy: 0.8598\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.3963 - accuracy: 0.8621 - val_loss: 0.4117 - val_accuracy: 0.8575\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.3932 - accuracy: 0.8630 - val_loss: 0.4071 - val_accuracy: 0.8584\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3903 - accuracy: 0.8647 - val_loss: 0.4086 - val_accuracy: 0.8585\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.3880 - accuracy: 0.8653 - val_loss: 0.4108 - val_accuracy: 0.8562\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.3863 - accuracy: 0.8655 - val_loss: 0.3904 - val_accuracy: 0.8646\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.3840 - accuracy: 0.8665 - val_loss: 0.3878 - val_accuracy: 0.8673\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.3817 - accuracy: 0.8677 - val_loss: 0.3996 - val_accuracy: 0.8619\n",
            "\n",
            "Accuracy: 86.19%\n",
            "\n",
            "learning rate: 2.0e-05\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 1.7174 - accuracy: 0.4134 - val_loss: 1.2207 - val_accuracy: 0.5464\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 1.0868 - accuracy: 0.5870 - val_loss: 0.9986 - val_accuracy: 0.6305\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.9468 - accuracy: 0.6518 - val_loss: 0.9026 - val_accuracy: 0.6724\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.8638 - accuracy: 0.6872 - val_loss: 0.8316 - val_accuracy: 0.7010\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.8025 - accuracy: 0.7134 - val_loss: 0.7813 - val_accuracy: 0.7223\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7606 - accuracy: 0.7303 - val_loss: 0.7480 - val_accuracy: 0.7333\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7340 - accuracy: 0.7389 - val_loss: 0.7263 - val_accuracy: 0.7400\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7160 - accuracy: 0.7453 - val_loss: 0.7121 - val_accuracy: 0.7455\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7023 - accuracy: 0.7508 - val_loss: 0.6989 - val_accuracy: 0.7519\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6910 - accuracy: 0.7558 - val_loss: 0.6890 - val_accuracy: 0.7566\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6814 - accuracy: 0.7604 - val_loss: 0.6797 - val_accuracy: 0.7611\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6732 - accuracy: 0.7642 - val_loss: 0.6720 - val_accuracy: 0.7651\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6661 - accuracy: 0.7670 - val_loss: 0.6649 - val_accuracy: 0.7673\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6598 - accuracy: 0.7697 - val_loss: 0.6599 - val_accuracy: 0.7685\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6542 - accuracy: 0.7715 - val_loss: 0.6546 - val_accuracy: 0.7714\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6493 - accuracy: 0.7732 - val_loss: 0.6489 - val_accuracy: 0.7738\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6448 - accuracy: 0.7747 - val_loss: 0.6447 - val_accuracy: 0.7748\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6407 - accuracy: 0.7759 - val_loss: 0.6419 - val_accuracy: 0.7742\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6368 - accuracy: 0.7771 - val_loss: 0.6368 - val_accuracy: 0.7765\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.6332 - accuracy: 0.7783 - val_loss: 0.6342 - val_accuracy: 0.7779\n",
            "\n",
            "Accuracy: 77.79%\n",
            "\n",
            "learning rate: 4.3e-05\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 64\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 1.4883 - accuracy: 0.4970 - val_loss: 1.0956 - val_accuracy: 0.5903\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.9833 - accuracy: 0.6382 - val_loss: 0.8912 - val_accuracy: 0.6783\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.8416 - accuracy: 0.6988 - val_loss: 0.8075 - val_accuracy: 0.7123\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7804 - accuracy: 0.7239 - val_loss: 0.7603 - val_accuracy: 0.7327\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7412 - accuracy: 0.7403 - val_loss: 0.7288 - val_accuracy: 0.7448\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.7154 - accuracy: 0.7497 - val_loss: 0.7075 - val_accuracy: 0.7553\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6968 - accuracy: 0.7577 - val_loss: 0.6914 - val_accuracy: 0.7612\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6826 - accuracy: 0.7635 - val_loss: 0.6795 - val_accuracy: 0.7656\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6712 - accuracy: 0.7678 - val_loss: 0.6689 - val_accuracy: 0.7676\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6621 - accuracy: 0.7710 - val_loss: 0.6600 - val_accuracy: 0.7701\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6545 - accuracy: 0.7738 - val_loss: 0.6536 - val_accuracy: 0.7739\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6480 - accuracy: 0.7753 - val_loss: 0.6472 - val_accuracy: 0.7745\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6423 - accuracy: 0.7766 - val_loss: 0.6425 - val_accuracy: 0.7754\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6372 - accuracy: 0.7780 - val_loss: 0.6373 - val_accuracy: 0.7772\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6328 - accuracy: 0.7791 - val_loss: 0.6330 - val_accuracy: 0.7786\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6286 - accuracy: 0.7802 - val_loss: 0.6301 - val_accuracy: 0.7799\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6247 - accuracy: 0.7811 - val_loss: 0.6256 - val_accuracy: 0.7799\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6210 - accuracy: 0.7823 - val_loss: 0.6220 - val_accuracy: 0.7806\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6174 - accuracy: 0.7833 - val_loss: 0.6178 - val_accuracy: 0.7833\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 5s 1ms/step - loss: 0.6139 - accuracy: 0.7846 - val_loss: 0.6146 - val_accuracy: 0.7832\n",
            "\n",
            "Accuracy: 78.32%\n",
            "\n",
            "learning rate: 8.1e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 56\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.7358 - accuracy: 0.7368 - val_loss: 0.6157 - val_accuracy: 0.7789\n",
            "Epoch 2/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5806 - accuracy: 0.7929 - val_loss: 0.5678 - val_accuracy: 0.7965\n",
            "Epoch 3/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.5302 - accuracy: 0.8111 - val_loss: 0.5518 - val_accuracy: 0.7994\n",
            "Epoch 4/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4903 - accuracy: 0.8262 - val_loss: 0.5131 - val_accuracy: 0.8109\n",
            "Epoch 5/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4621 - accuracy: 0.8361 - val_loss: 0.4442 - val_accuracy: 0.8427\n",
            "Epoch 6/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4394 - accuracy: 0.8437 - val_loss: 0.4388 - val_accuracy: 0.8431\n",
            "Epoch 7/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4203 - accuracy: 0.8512 - val_loss: 0.4464 - val_accuracy: 0.8424\n",
            "Epoch 8/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.4039 - accuracy: 0.8568 - val_loss: 0.4335 - val_accuracy: 0.8431\n",
            "Epoch 9/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3915 - accuracy: 0.8608 - val_loss: 0.4160 - val_accuracy: 0.8518\n",
            "Epoch 10/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3814 - accuracy: 0.8643 - val_loss: 0.3796 - val_accuracy: 0.8663\n",
            "Epoch 11/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3726 - accuracy: 0.8683 - val_loss: 0.3940 - val_accuracy: 0.8587\n",
            "Epoch 12/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3657 - accuracy: 0.8710 - val_loss: 0.3811 - val_accuracy: 0.8646\n",
            "Epoch 13/20\n",
            "3618/3618 [==============================] - 7s 2ms/step - loss: 0.3603 - accuracy: 0.8725 - val_loss: 0.4124 - val_accuracy: 0.8532\n",
            "Epoch 14/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3548 - accuracy: 0.8748 - val_loss: 0.3828 - val_accuracy: 0.8633\n",
            "Epoch 15/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3507 - accuracy: 0.8761 - val_loss: 0.3679 - val_accuracy: 0.8718\n",
            "Epoch 16/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3481 - accuracy: 0.8772 - val_loss: 0.3843 - val_accuracy: 0.8664\n",
            "Epoch 17/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3447 - accuracy: 0.8787 - val_loss: 0.3709 - val_accuracy: 0.8671\n",
            "Epoch 18/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3425 - accuracy: 0.8796 - val_loss: 0.3672 - val_accuracy: 0.8734\n",
            "Epoch 19/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3415 - accuracy: 0.8807 - val_loss: 0.3663 - val_accuracy: 0.8730\n",
            "Epoch 20/20\n",
            "3618/3618 [==============================] - 6s 2ms/step - loss: 0.3394 - accuracy: 0.8809 - val_loss: 0.3521 - val_accuracy: 0.8739\n",
            "\n",
            "Accuracy: 87.39%\n",
            "\n",
            "CPU times: user 1h 32min 30s, sys: 5min 23s, total: 1h 37min 53s\n",
            "Wall time: 1h 14min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lUZ2coUsWAk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "1c4beb29-158d-4144-cf20-74ffbd60cff0"
      },
      "source": [
        "# plotea los valores optimizados aluego de n iteraciones\n",
        "plot_convergence(search_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f170f0be7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1O3qqS9sY1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898023a4-23cf-4b4d-e734-547820ea3946"
      },
      "source": [
        "search_result.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0008563342297808483, 5, 64, 'relu']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9i73kyMs6xT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bccfc2-1825-4d4d-f0d0-ed0777d7fd0f"
      },
      "source": [
        "search_result.fun"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.8896490931510925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdNtUSNCvN-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "c857dbc0-8491-4b57-cfe4-e862beb7021b"
      },
      "source": [
        "fig, ax = plot_objective(result=search_result, plot_dims=['learning_rate', 'num_dense_nodes', 'num_dense_layers'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a248a4e92930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_dense_nodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_dense_layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ucoQErttD3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f011441-22ed-409f-fcae-d54178063eb7"
      },
      "source": [
        "sorted(zip(search_result.func_vals, search_result.x_iters))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-0.8896490931510925, [0.0008563342297808483, 5, 64, 'relu']),\n",
              " (-0.8844658732414246, [0.000643983419803121, 5, 64, 'relu']),\n",
              " (-0.8834119439125061, [0.0007972965968572502, 5, 64, 'relu']),\n",
              " (-0.8829454779624939, [0.0006959414947765679, 5, 64, 'relu']),\n",
              " (-0.8756025433540344, [0.00053805926948173, 5, 64, 'relu']),\n",
              " (-0.8739439249038696, [0.0008083623215973162, 5, 56, 'relu']),\n",
              " (-0.8715078234672546, [0.0011959024320921496, 5, 64, 'relu']),\n",
              " (-0.8681214451789856, [0.0007365054613813541, 5, 46, 'relu']),\n",
              " (-0.8673784732818604, [0.0003567115283423288, 5, 60, 'relu']),\n",
              " (-0.8657025694847107, [0.0016034681316048727, 5, 58, 'relu']),\n",
              " (-0.8635601997375488, [0.0007487751388150632, 4, 64, 'relu']),\n",
              " (-0.8618842959403992, [0.0013758574458821477, 4, 37, 'relu']),\n",
              " (-0.8491162657737732, [0.0022963777514262485, 5, 36, 'relu']),\n",
              " (-0.8483042120933533, [0.000329251414402943, 5, 47, 'relu']),\n",
              " (-0.8322708010673523, [0.0016149111332506218, 4, 63, 'relu']),\n",
              " (-0.8311477303504944, [0.0001166423953217995, 5, 64, 'relu']),\n",
              " (-0.8295063972473145, [0.00037039786448533863, 3, 43, 'relu']),\n",
              " (-0.815528929233551, [0.001625087336425507, 1, 64, 'relu']),\n",
              " (-0.8135074973106384, [0.004, 2, 16, 'relu']),\n",
              " (-0.8128163814544678, [0.0011504111271087765, 2, 21, 'relu']),\n",
              " (-0.8115032911300659, [0.01, 1, 64, 'relu']),\n",
              " (-0.8081514835357666, [0.0019843310622886957, 1, 40, 'relu']),\n",
              " (-0.803883969783783, [0.009968415767224147, 1, 35, 'relu']),\n",
              " (-0.8001347780227661, [0.0010617692857575892, 2, 15, 'relu']),\n",
              " (-0.7929646372795105, [0.0005408243032239853, 4, 14, 'relu']),\n",
              " (-0.7899583578109741, [0.004009285003392854, 2, 10, 'relu']),\n",
              " (-0.7831683158874512, [4.290208589982648e-05, 3, 64, 'relu']),\n",
              " (-0.7798856496810913, [7.515669962098201e-05, 5, 26, 'relu']),\n",
              " (-0.7779160141944885, [1.9950960494817054e-05, 5, 64, 'relu']),\n",
              " (-0.777052104473114, [0.0001901553806258021, 1, 63, 'relu']),\n",
              " (-0.754090428352356, [0.01, 5, 64, 'relu']),\n",
              " (-0.7520862221717834, [0.008906941677490511, 1, 6, 'relu']),\n",
              " (-0.7499092817306519, [0.00989642017491324, 5, 36, 'relu']),\n",
              " (-0.7469548583030701, [0.009807139410195566, 5, 6, 'relu']),\n",
              " (-0.7156827449798584, [0.0010176691763584603, 5, 5, 'relu']),\n",
              " (-0.6268249154090881, [3.0041497461509075e-05, 2, 7, 'relu']),\n",
              " (-0.5786209106445312, [5.640581672606509e-06, 4, 20, 'relu']),\n",
              " (-0.5293975472450256, [2.2311416042040268e-06, 4, 27, 'relu']),\n",
              " (-0.495792955160141, [1.5235074182568423e-06, 4, 40, 'relu']),\n",
              " (-0.43641045689582825, [1.050849938351439e-06, 1, 61, 'relu'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQk3ROiHt6SI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b527e5-766d-454f-e904-966e1f9fd8af"
      },
      "source": [
        "model = load_model(path_best_model)\n",
        "result = model.evaluate(x=X_test,\n",
        "                        y=y_test)\n",
        "print(\"Accuracy: {0:.12%}\".format(result[1]))\n",
        "print(\"Loss: {0:.2%}\".format(result[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1809/1809 [==============================] - 2s 888us/step - loss: 0.3265 - accuracy: 0.8897\n",
            "Accuracy: 88.972008228302%\n",
            "Loss: 32.65%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}